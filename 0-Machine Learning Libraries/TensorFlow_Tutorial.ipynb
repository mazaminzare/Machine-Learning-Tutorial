{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1d161de9",
      "metadata": {
        "id": "1d161de9"
      },
      "source": [
        "## 1. Installation\n",
        "Ensure you have Python installed. You can install TensorFlow with the following command:\n",
        "```bash\n",
        "pip install tensorflow\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7bb7088",
      "metadata": {
        "id": "f7bb7088"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9511c933",
      "metadata": {
        "id": "9511c933"
      },
      "source": [
        "## 2. Basics of Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4169f66a",
      "metadata": {
        "id": "4169f66a"
      },
      "outputs": [],
      "source": [
        "# Creating Tensors with TensorFlow\n",
        "x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "y = tf.random.uniform((2, 2))\n",
        "z = tf.zeros((2, 2))\n",
        "w = tf.ones((2, 2))\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "print(w)\n",
        "\n",
        "# Tensor Operations\n",
        "add_result = x + y\n",
        "mul_result = x * y\n",
        "dot_result = tf.linalg.matmul(x, y)\n",
        "\n",
        "print(add_result)\n",
        "print(mul_result)\n",
        "print(dot_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b3a635",
      "metadata": {
        "id": "39b3a635"
      },
      "source": [
        "## 3. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b54893",
      "metadata": {
        "id": "b2b54893"
      },
      "outputs": [],
      "source": [
        "# Using ImageDataGenerator for data loading and augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd252925",
      "metadata": {
        "id": "bd252925"
      },
      "source": [
        "## 4. Building Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93aa5e9",
      "metadata": {
        "id": "a93aa5e9"
      },
      "outputs": [],
      "source": [
        "# Define a simple neural network using Sequential API\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2d6c4f",
      "metadata": {
        "id": "be2d6c4f"
      },
      "source": [
        "## 5. Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f0a1389",
      "metadata": {
        "id": "3f0a1389"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=SGD(learning_rate=0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a950742c",
      "metadata": {
        "id": "a950742c"
      },
      "source": [
        "## 6. Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c718a3",
      "metadata": {
        "id": "42c718a3"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=5, validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4f11144",
      "metadata": {
        "id": "c4f11144"
      },
      "source": [
        "## 7. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03ee2963",
      "metadata": {
        "id": "03ee2963"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'Accuracy: {accuracy * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e3b32d",
      "metadata": {
        "id": "39e3b32d"
      },
      "source": [
        "## 8. Saving and Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aea28c2",
      "metadata": {
        "id": "8aea28c2"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('simple_model.h5')\n",
        "\n",
        "# Load the model\n",
        "new_model = tf.keras.models.load_model('simple_model.h5')\n",
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "505fe362",
      "metadata": {
        "id": "505fe362"
      },
      "source": [
        "## 9. Moving to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10cf51b9",
      "metadata": {
        "id": "10cf51b9"
      },
      "outputs": [],
      "source": [
        "# Ensure the operations are running on the GPU\n",
        "with tf.device('/GPU:0'):\n",
        "    x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "    y = tf.random.uniform((2, 2))\n",
        "    z = tf.zeros((2, 2))\n",
        "    w = tf.ones((2, 2))\n",
        "\n",
        "    print(x)\n",
        "    print(y)\n",
        "    print(z)\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dda244d",
      "metadata": {
        "id": "6dda244d"
      },
      "source": [
        "## 10. Advanced Topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "861ac69a",
      "metadata": {
        "id": "861ac69a"
      },
      "outputs": [],
      "source": [
        "# Custom Data Generator\n",
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, csv_file, root_dir, batch_size=32, dim=(150, 150), n_channels=3, n_classes=10, shuffle=True):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.annotations) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_annotations = [self.annotations.iloc[k] for k in indexes]\n",
        "        X, y = self.__data_generation(batch_annotations)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.annotations))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, batch_annotations):\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "        for i, annotation in enumerate(batch_annotations):\n",
        "            img_name = os.path.join(self.root_dir, annotation[0])\n",
        "            image = Image.open(img_name)\n",
        "            image = image.resize(self.dim)\n",
        "            X[i,] = np.array(image) / 255.0\n",
        "            y[i] = annotation[1]\n",
        "        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13bb2bbb",
      "metadata": {
        "id": "13bb2bbb"
      },
      "source": [
        "### Custom Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8befca8",
      "metadata": {
        "id": "a8befca8"
      },
      "outputs": [],
      "source": [
        "# Custom training loop\n",
        "def custom_train_model(model, train_generator, val_generator, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Starting epoch {epoch+1}/{epochs}')\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_generator):\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = model(x_batch_train, training=True)\n",
        "                loss_value = tf.keras.losses.sparse_categorical_crossentropy(y_batch_train, logits)\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "            if step % 100 == 0:\n",
        "                print(f'Epoch {epoch+1} Step {step}: Loss = {loss_value.numpy().mean()}')\n",
        "\n",
        "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        for x_batch_val, y_batch_val in val_generator:\n",
        "            val_logits = model(x_batch_val, training=False)\n",
        "            val_accuracy.update_state(y_batch_val, val_logits)\n",
        "        print(f'Validation accuracy: {val_accuracy.result().numpy()}')\n",
        "\n",
        "# Usage example\n",
        "model.compile(optimizer=SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy')\n",
        "custom_train_model(model, train_generator, validation_generator, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e179a1",
      "metadata": {
        "id": "d1e179a1"
      },
      "source": [
        "### Custom Testing Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a96970d",
      "metadata": {
        "id": "3a96970d"
      },
      "outputs": [],
      "source": [
        "# Custom testing loop\n",
        "def custom_test_model(model, test_generator):\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    for x_batch_test, y_batch_test in test_generator:\n",
        "        test_logits = model(x_batch_test, training=False)\n",
        "        test_accuracy.update_state(y_batch_test, test_logits)\n",
        "    print(f'Test accuracy: {test_accuracy.result().numpy()}')\n",
        "\n",
        "# Usage example\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'data/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "custom_test_model(model, test_generator)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}