{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d7fb617",
      "metadata": {
        "id": "4d7fb617"
      },
      "source": [
        "## 1. Installation\n",
        "Ensure you have Python installed. You can install Keras with the following command:\n",
        "```bash\n",
        "pip install keras tensorflow\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77427f93",
      "metadata": {
        "id": "77427f93"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe9e3a6",
      "metadata": {
        "id": "ffe9e3a6"
      },
      "source": [
        "## 2. Basics of Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669d2fcb",
      "metadata": {
        "id": "669d2fcb"
      },
      "outputs": [],
      "source": [
        "# Creating Tensors with TensorFlow\n",
        "x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "y = tf.random.uniform((2, 2))\n",
        "z = tf.zeros((2, 2))\n",
        "w = tf.ones((2, 2))\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "print(w)\n",
        "\n",
        "# Tensor Operations\n",
        "add_result = x + y\n",
        "mul_result = x * y\n",
        "dot_result = tf.linalg.matmul(x, y)\n",
        "\n",
        "print(add_result)\n",
        "print(mul_result)\n",
        "print(dot_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4b4903",
      "metadata": {
        "id": "ab4b4903"
      },
      "source": [
        "## 3. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81a7502",
      "metadata": {
        "id": "c81a7502"
      },
      "outputs": [],
      "source": [
        "# Using ImageDataGenerator for data loading and augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c81ddae",
      "metadata": {
        "id": "9c81ddae"
      },
      "source": [
        "## 4. Building Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe8c9df",
      "metadata": {
        "id": "6fe8c9df"
      },
      "outputs": [],
      "source": [
        "# Define a simple neural network using Sequential API\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "befbcc0d",
      "metadata": {
        "id": "befbcc0d"
      },
      "source": [
        "## 5. Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c81750e",
      "metadata": {
        "id": "0c81750e"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=SGD(learning_rate=0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1a96dc",
      "metadata": {
        "id": "0b1a96dc"
      },
      "source": [
        "## 6. Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1144e9",
      "metadata": {
        "id": "eb1144e9"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=5, validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80541504",
      "metadata": {
        "id": "80541504"
      },
      "source": [
        "## 7. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3498a76",
      "metadata": {
        "id": "c3498a76"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'Accuracy: {accuracy * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30166586",
      "metadata": {
        "id": "30166586"
      },
      "source": [
        "## 8. Saving and Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f7b0df8",
      "metadata": {
        "id": "5f7b0df8"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('simple_model.h5')\n",
        "\n",
        "# Load the model\n",
        "new_model = tf.keras.models.load_model('simple_model.h5')\n",
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c01ad7d",
      "metadata": {
        "id": "1c01ad7d"
      },
      "source": [
        "## 9. Moving to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73dba976",
      "metadata": {
        "id": "73dba976"
      },
      "outputs": [],
      "source": [
        "# Ensure the operations are running on the GPU\n",
        "with tf.device('/GPU:0'):\n",
        "    x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "    y = tf.random.uniform((2, 2))\n",
        "    z = tf.zeros((2, 2))\n",
        "    w = tf.ones((2, 2))\n",
        "\n",
        "    print(x)\n",
        "    print(y)\n",
        "    print(z)\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2971c0c2",
      "metadata": {
        "id": "2971c0c2"
      },
      "source": [
        "## 10. Advanced Topics\n",
        "\n",
        "### Custom Data Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e52fb9",
      "metadata": {
        "id": "a1e52fb9"
      },
      "outputs": [],
      "source": [
        "# Custom data reading\n",
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, csv_file, root_dir, batch_size=32, dim=(150, 150), n_channels=3, n_classes=10, shuffle=True):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.annotations) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_annotations = [self.annotations.iloc[k] for k in indexes]\n",
        "        X, y = self.__data_generation(batch_annotations)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.annotations))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, batch_annotations):\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "        for i, annotation in enumerate(batch_annotations):\n",
        "            img_name = os.path.join(self.root_dir, annotation[0])\n",
        "            image = Image.open(img_name)\n",
        "            image = image.resize(self.dim)\n",
        "            X[i,] = np.array(image) / 255.0\n",
        "            y[i] = annotation[1]\n",
        "        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
        "\n",
        "# Usage example\n",
        "custom_data_gen = CustomDataGenerator(csv_file='data/labels.csv', root_dir='data/images', batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc7ede5",
      "metadata": {
        "id": "fdc7ede5"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a40a557",
      "metadata": {
        "id": "4a40a557"
      },
      "outputs": [],
      "source": [
        "# Using a learning rate scheduler\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "model.compile(optimizer=SGD(learning_rate=lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training with the scheduler\n",
        "history = model.fit(train_generator, epochs=5, validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18b17957",
      "metadata": {
        "id": "18b17957"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c301a8",
      "metadata": {
        "id": "59c301a8"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "data_augmentation = Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "# Apply data augmentation in the dataset\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=data_augmentation)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc5dd18",
      "metadata": {
        "id": "1bc5dd18"
      },
      "source": [
        "### Custom Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "878895dd",
      "metadata": {
        "id": "878895dd"
      },
      "outputs": [],
      "source": [
        "# Custom data augmentation\n",
        "def custom_augmentation(image):\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.image.adjust_contrast(image, 2)\n",
        "    return image\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=custom_augmentation)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20dcb25a",
      "metadata": {
        "id": "20dcb25a"
      },
      "source": [
        "### Custom Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc1b1b34",
      "metadata": {
        "id": "dc1b1b34"
      },
      "outputs": [],
      "source": [
        "# Custom training loop\n",
        "def custom_train_model(model, train_generator, val_generator, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Starting epoch {epoch+1}/{epochs}')\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_generator):\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = model(x_batch_train, training=True)\n",
        "                loss_value = tf.keras.losses.sparse_categorical_crossentropy(y_batch_train, logits)\n",
        "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "            model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "            if step % 100 == 0:\n",
        "                print(f'Epoch {epoch+1} Step {step}: Loss = {loss_value.numpy().mean()}')\n",
        "\n",
        "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        for x_batch_val, y_batch_val in val_generator:\n",
        "            val_logits = model(x_batch_val, training=False)\n",
        "            val_accuracy.update_state(y_batch_val, val_logits)\n",
        "        print(f'Validation accuracy: {val_accuracy.result().numpy()}')\n",
        "\n",
        "# Usage example\n",
        "model.compile(optimizer=SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy')\n",
        "custom_train_model(model, train_generator, validation_generator, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "994466f5",
      "metadata": {
        "id": "994466f5"
      },
      "source": [
        "### Custom Testing Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06993126",
      "metadata": {
        "id": "06993126"
      },
      "outputs": [],
      "source": [
        "# Custom testing loop\n",
        "def custom_test_model(model, test_generator):\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    for x_batch_test, y_batch_test in test_generator:\n",
        "        test_logits = model(x_batch_test, training=False)\n",
        "        test_accuracy.update_state(y_batch_test, test_logits)\n",
        "    print(f'Test accuracy: {test_accuracy.result().numpy()}')\n",
        "\n",
        "# Usage example\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'data/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "custom_test_model(model, test_generator)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}