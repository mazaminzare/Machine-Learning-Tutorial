{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3a1780d",
      "metadata": {
        "id": "a3a1780d"
      },
      "source": [
        "## 1. Installation\n",
        "Ensure you have Python installed. You can install PyTorch with the following command:\n",
        "```bash\n",
        "pip install torch torchvision\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bb84f4d",
      "metadata": {
        "id": "5bb84f4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the image\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Custom Dataset example\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89216f31",
      "metadata": {
        "id": "89216f31"
      },
      "source": [
        "## 2. Basics of Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64412d42",
      "metadata": {
        "id": "64412d42"
      },
      "outputs": [],
      "source": [
        "# Creating Tensors\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = torch.rand(2, 2)\n",
        "z = torch.zeros(2, 2)\n",
        "w = torch.ones(2, 2)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "print(w)\n",
        "\n",
        "# Tensor Operations\n",
        "add_result = x + y\n",
        "mul_result = x * y\n",
        "dot_result = torch.matmul(x, y)\n",
        "\n",
        "print(add_result)\n",
        "print(mul_result)\n",
        "print(dot_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c176c9d",
      "metadata": {
        "id": "2c176c9d"
      },
      "source": [
        "## 3. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e404d816",
      "metadata": {
        "id": "e404d816"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = datasets.MNIST('mnist_data/', download=True, train=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "data_iter = iter(trainloader)\n",
        "images, labels = next(data_iter)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4b38d80",
      "metadata": {
        "id": "e4b38d80"
      },
      "source": [
        "## 4. Building Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b941a523",
      "metadata": {
        "id": "b941a523"
      },
      "outputs": [],
      "source": [
        "net = SimpleNet()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a663938",
      "metadata": {
        "id": "8a663938"
      },
      "source": [
        "## 5. Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370e6851",
      "metadata": {
        "id": "370e6851"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "045b0214",
      "metadata": {
        "id": "045b0214"
      },
      "source": [
        "## 6. Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c502ef60",
      "metadata": {
        "id": "c502ef60"
      },
      "outputs": [],
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()  # zero the parameter gradients\n",
        "\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch + 1}, Loss: {running_loss/len(trainloader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80a7840f",
      "metadata": {
        "id": "80a7840f"
      },
      "source": [
        "## 7. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5226dbd0",
      "metadata": {
        "id": "5226dbd0"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in trainloader:\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "891be8a6",
      "metadata": {
        "id": "891be8a6"
      },
      "source": [
        "## 8. Saving and Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da4945a9",
      "metadata": {
        "id": "da4945a9"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'simple_net.pth')\n",
        "net.load_state_dict(torch.load('simple_net.pth'))\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989ac112",
      "metadata": {
        "id": "989ac112"
      },
      "source": [
        "## 9. Moving to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a344af02",
      "metadata": {
        "id": "a344af02"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = x.to(device)\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78beb532",
      "metadata": {
        "id": "78beb532"
      },
      "source": [
        "## 10. Advanced Topics\n",
        "\n",
        "### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c25709f1",
      "metadata": {
        "id": "c25709f1"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained ResNet model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze the feature extraction layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final layer to match the number of classes in the new dataset\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "# Move the model to GPU\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train only the final layer\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch + 1}, Loss: {running_loss/len(trainloader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "716cf262",
      "metadata": {
        "id": "716cf262"
      },
      "source": [
        "## Custom Data Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb6c197",
      "metadata": {
        "id": "0bb6c197"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "# Example of custom data reading\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[idx, 1]))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)\n",
        "\n",
        "# Usage example\n",
        "custom_dataset = CustomImageDataset(csv_file='data/labels.csv', root_dir='data/images', transform=transform)\n",
        "custom_loader = DataLoader(custom_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd8bdab",
      "metadata": {
        "id": "2dd8bdab"
      },
      "source": [
        "## Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33165841",
      "metadata": {
        "id": "33165841"
      },
      "outputs": [],
      "source": [
        "# Using a learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "# Training loop with scheduler step\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()  # Step the learning rate scheduler\n",
        "    print(f'Epoch {epoch + 1}, Loss: {running_loss/len(trainloader)}, Learning Rate: {scheduler.get_last_lr()[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec01100",
      "metadata": {
        "id": "cec01100"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229a86f4",
      "metadata": {
        "id": "229a86f4"
      },
      "outputs": [],
      "source": [
        "# Data augmentation with torchvision transforms\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Apply data augmentation in the dataset\n",
        "augmented_dataset = datasets.ImageFolder(root='data/train', transform=data_transforms)\n",
        "augmented_loader = DataLoader(augmented_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0254d714",
      "metadata": {
        "id": "0254d714"
      },
      "source": [
        "## Custom Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c787e7e5",
      "metadata": {
        "id": "c787e7e5"
      },
      "outputs": [],
      "source": [
        "# Custom data augmentation\n",
        "class CustomAugmentation:\n",
        "    def __call__(self, image):\n",
        "        # Example: Convert image to grayscale and then back to RGB\n",
        "        image = transforms.functional.to_grayscale(image, num_output_channels=3)\n",
        "        image = transforms.functional.adjust_contrast(image, 2)\n",
        "        return image\n",
        "\n",
        "custom_transforms = transforms.Compose([\n",
        "    CustomAugmentation(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "\n",
        "# Apply custom data augmentation in the dataset\n",
        "custom_augmented_dataset = CustomImageDataset(csv_file='data/labels.csv', root_dir='data/images', transform=custom_transforms)\n",
        "custom_augmented_loader = DataLoader(custom_augmented_dataset, batch_size=64, shuffle=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}