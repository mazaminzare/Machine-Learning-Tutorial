{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarial Autoencoder (AAE) Tutorial\n",
        "\n",
        "## Introduction\n",
        "\n",
        "An Adversarial Autoencoder (AAE) is a type of autoencoder that incorporates the principles of Generative Adversarial Networks (GANs) to impose a prior distribution on the latent space. This allows the AAE to learn more structured latent representations and generate more realistic samples.\n",
        "\n",
        "## Architecture\n",
        "\n",
        "An AAE consists of three main components:\n",
        "1. **Encoder**: Maps the input to a latent-space representation.\n",
        "2. **Decoder**: Reconstructs the input from the latent space representation.\n",
        "3. **Discriminator**: Distinguishes between true samples from a prior distribution and encoded samples from the latent space.\n",
        "\n",
        "### Encoder\n",
        "\n",
        "The encoder function, $z = f(x)$, maps the input $x$ to a latent representation $z$. Mathematically, this can be written as:\n",
        "\n",
        "$$\n",
        "z = f(x) = \\sigma(Wx + b)\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $W$ is a weight matrix\n",
        "- $b$ is a bias vector\n",
        "- $\\sigma$ is an activation function (e.g., ReLU, sigmoid)\n",
        "\n",
        "### Decoder\n",
        "\n",
        "The decoder function, $\\hat{x} = g(z)$, maps the latent representation $z$ back to the original input space. Mathematically, this can be written as:\n",
        "\n",
        "$$\n",
        "\\hat{x} = g(z) = \\sigma(W'z + b')\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $W'$ is a weight matrix (not necessarily the transpose of $W$)\n",
        "- $b'$ is a bias vector\n",
        "- $\\sigma$ is an activation function\n",
        "\n",
        "### Discriminator\n",
        "\n",
        "The discriminator function, $D(z)$, distinguishes between true samples from the prior distribution and encoded samples from the latent space. Mathematically, this can be written as:\n",
        "\n",
        "$$\n",
        "D(z) = \\text{sigmoid}(W''z + b'')\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $W''$ is a weight matrix\n",
        "- $b''$ is a bias vector\n",
        "\n",
        "## Loss Function\n",
        "\n",
        "The loss function for an AAE consists of three parts:\n",
        "1. **Reconstruction Loss**: Measures how well the decoder reconstructs the input.\n",
        "2. **Adversarial Loss (Discriminator)**: Measures how well the discriminator distinguishes between true and encoded samples.\n",
        "3. **Adversarial Loss (Generator/Encoder)**: Measures how well the encoder fools the discriminator.\n",
        "\n",
        "The total loss is:\n",
        "\n",
        "$$\n",
        "L = \\text{Reconstruction Loss} + \\lambda_1 \\cdot \\text{Adversarial Loss (Discriminator)} + \\lambda_2 \\cdot \\text{Adversarial Loss (Generator/Encoder)}\n",
        "$$\n",
        "\n",
        "#### Reconstruction Loss\n",
        "\n",
        "The reconstruction loss is typically the mean squared error (MSE):\n",
        "\n",
        "$$\n",
        "\\text{Reconstruction Loss} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\hat{x}_i)^2\n",
        "$$\n",
        "\n",
        "#### Adversarial Loss (Discriminator)\n",
        "\n",
        "The adversarial loss for the discriminator is the binary cross-entropy loss:\n",
        "\n",
        "$$\n",
        "\\text{Adversarial Loss (Discriminator)} = -\\left( \\mathbb{E}_{z \\sim P_z}[\\log D(z)] + \\mathbb{E}_{z \\sim Q_z}[\\log (1 - D(z))] \\right)\n",
        "$$\n",
        "\n",
        "where $P_z$ is the prior distribution and $Q_z$ is the distribution of encoded samples.\n",
        "\n",
        "#### Adversarial Loss (Generator/Encoder)\n",
        "\n",
        "The adversarial loss for the generator/encoder is also the binary cross-entropy loss, but with flipped labels:\n",
        "\n",
        "$$\n",
        "\\text{Adversarial Loss (Generator/Encoder)} = -\\mathbb{E}_{z \\sim Q_z}[\\log D(z)]\n",
        "$$\n",
        "\n",
        "## Training Process\n",
        "\n",
        "Training an AAE involves alternating between optimizing the encoder/decoder and the discriminator.\n",
        "\n",
        "### Derivatives\n",
        "\n",
        "Let's derive the gradients for the encoder/decoder and discriminator weights.\n",
        "\n",
        "#### Decoder Gradients\n",
        "\n",
        "For the decoder, the gradient of the loss function with respect to the decoder weights $W'$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W'} = \\frac{\\partial L}{\\partial \\hat{x}} \\cdot \\frac{\\partial \\hat{x}}{\\partial W'}\n",
        "$$\n",
        "\n",
        "Since $\\hat{x} = \\sigma(W'z + b')$, we have:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\hat{x}}{\\partial W'} = z \\cdot \\sigma'(W'z + b')\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W'} = (x - \\hat{x}) \\cdot \\sigma'(W'z + b') \\cdot z^T\n",
        "$$\n",
        "\n",
        "#### Encoder Gradients\n",
        "\n",
        "For the encoder, the gradient of the loss function with respect to the encoder weights $W$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial W} + \\lambda_2 \\cdot \\frac{\\partial \\text{Adversarial Loss (Generator/Encoder)}}{\\partial W}\n",
        "$$\n",
        "\n",
        "Since $z = \\sigma(Wx + b)$, we have:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial z} = \\frac{\\partial L}{\\partial \\hat{x}} \\cdot \\frac{\\partial \\hat{x}}{\\partial z} = (x - \\hat{x}) \\cdot \\sigma'(W'z + b') \\cdot W'^T\n",
        "$$\n",
        "\n",
        "And,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z}{\\partial W} = x \\cdot \\sigma'(Wx + b)\n",
        "$$\n",
        "\n",
        "The gradient of the adversarial loss with respect to $W$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{Adversarial Loss (Generator/Encoder)}}{\\partial W} = -\\frac{1}{D(z)} \\cdot \\frac{\\partial D(z)}{\\partial W}\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W} = [(x - \\hat{x}) \\cdot \\sigma'(W'z + b') \\cdot W'^T] \\cdot x^T \\cdot \\sigma'(Wx + b) - \\lambda_2 \\cdot \\frac{1}{D(z)} \\cdot \\frac{\\partial D(z)}{\\partial W}\n",
        "$$\n",
        "\n",
        "### Discriminator Gradients\n",
        "\n",
        "For the discriminator, the gradient of the loss function with respect to the discriminator weights $W''$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W''} = \\frac{\\partial \\text{Adversarial Loss (Discriminator)}}{\\partial W''}\n",
        "$$\n",
        "\n",
        "Since $D(z) = \\text{sigmoid}(W''z + b'')$, we have:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial D(z)}{\\partial W''} = z \\cdot \\sigma'(W''z + b'')\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{Adversarial Loss (Discriminator)}}{\\partial W''} = \\left( \\frac{1}{D(z)} \\cdot \\frac{\\partial D(z)}{\\partial W''} - \\frac{1}{1 - D(z)} \\cdot \\frac{\\partial (1 - D(z))}{\\partial W''} \\right)\n",
        "$$\n",
        "\n",
        "### Gradient Descent Update\n",
        "\n",
        "The weights and biases are updated using the gradients:\n",
        "\n",
        "$$\n",
        "W \\leftarrow W - \\eta \\frac{\\partial L}{\\partial W}\n",
        "$$\n",
        "\n",
        "$$\n",
        "b \\leftarrow b - \\eta \\frac{\\partial L}{\\partial b}\n",
        "$$\n",
        "\n",
        "where $\\eta$ is the learning rate.\n",
        "\n",
        "### Advantages and Drawbacks\n",
        "\n",
        "#### Advantages\n",
        "- **Structured Latent Space**: AAEs impose a prior distribution on the latent space, leading to more structured and interpretable latent representations.\n",
        "- **Realistic Sample Generation**: By leveraging the adversarial training mechanism, AAEs can generate more realistic samples compared to traditional autoencoders.\n",
        "- **Flexibility**: AAEs allow for flexible and customizable prior distributions on the latent space, enabling various applications such as semi-supervised learning and disentangled representation learning.\n",
        "\n",
        "#### Drawbacks\n",
        "- **Complex Training**: Training AAEs involves alternating between optimizing the encoder/decoder and the discriminator, which can be challenging and time-consuming.\n",
        "- **Mode Collapse**: Similar to GANs, AAEs can suffer from mode collapse, where the generator/encoder produces limited diversity in the generated samples.\n",
        "- **Hyperparameter Sensitivity**: AAEs require careful tuning of hyperparameters, such as the learning rate and the balance between the reconstruction and adversarial losses.\n",
        "\n",
        "### Innovations of Adversarial Autoencoders (AAEs)\n",
        "\n",
        "#### Combining Autoencoders and GANs\n",
        "- **Autoencoders**: Traditionally used for learning efficient codings of input data by minimizing reconstruction loss.\n",
        "- **GANs**: Designed to generate realistic data samples by training a generator and discriminator in a competitive setting.\n",
        "- **AAEs**: Integrate the autoencoder architecture with adversarial training, where the latent space learned by the encoder is regularized to follow a prior distribution using a discriminator.\n",
        "\n",
        "#### Regularization of Latent Space\n",
        "- **Prior Distribution**: The encoder is regularized to produce latent codes that follow a specific prior distribution (e.g., Gaussian, mixture of Gaussians). This regularization is enforced by training a discriminator to differentiate between true samples from the prior and encoded samples.\n",
        "- **Structured Latent Space**: Ensures that the latent space has a well-defined structure, leading to more meaningful and interpretable representations. This is crucial for tasks like interpolation, clustering, and generation of diverse samples.\n",
        "\n",
        "#### Improved Sample Generation\n",
        "- **Realistic Samples**: By employing adversarial training, AAEs can generate more realistic and diverse samples compared to traditional autoencoders.\n",
        "- **Mode Coverage**: Adversarial training helps the encoder learn a latent space that covers the true data distribution more effectively, reducing issues like mode collapse that are common in standard GANs.\n",
        "\n",
        "#### Flexibility in Prior Distribution\n",
        "- **Customizable Priors**: AAEs allow for the use of various prior distributions on the latent space, providing flexibility for different applications. For example, a mixture of Gaussians can be used for clustering, and a Gaussian prior can be used for smooth interpolations.\n",
        "- **Application in Semi-Supervised Learning**: The structured latent space can facilitate semi-supervised learning by providing meaningful clusters in the latent space.\n",
        "\n",
        "#### Stability in Training\n",
        "- **Combining MSE and Adversarial Loss**: The reconstruction loss (e.g., Mean Squared Error) combined with adversarial loss provides a stabilizing effect during training. The reconstruction loss ensures that the autoencoder retains the essential features of the input, while the adversarial loss regularizes the latent space.\n",
        "- **Reduced Mode Collapse**: By balancing the autoencoder and adversarial objectives, AAEs can achieve a more stable training process compared to standard GANs, reducing the likelihood of mode collapse.\n",
        "\n",
        "## Numerical Example\n",
        "\n",
        "Let's consider a numerical example using Python and Keras to illustrate how an AAE works. We'll use the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bdCvHZMPiV64"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmvXgXNthrC5",
        "outputId": "3936c259-ba56-4ad2-f66f-3c4727f61bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 49466098.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1847256.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 13487632.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5253868.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] | G Loss: 5.5588 | D Loss: 0.3284\n",
            "Epoch [2/50] | G Loss: 3.4995 | D Loss: 0.1180\n",
            "Epoch [3/50] | G Loss: 4.5743 | D Loss: 0.0086\n",
            "Epoch [4/50] | G Loss: 5.0441 | D Loss: 0.0094\n",
            "Epoch [5/50] | G Loss: 5.6633 | D Loss: 0.0038\n",
            "Epoch [6/50] | G Loss: 5.9425 | D Loss: 0.0025\n",
            "Epoch [7/50] | G Loss: 6.5514 | D Loss: 0.0010\n",
            "Epoch [8/50] | G Loss: 6.7419 | D Loss: 0.0008\n",
            "Epoch [9/50] | G Loss: 12.9642 | D Loss: 0.0619\n",
            "Epoch [10/50] | G Loss: 5.9849 | D Loss: 0.0017\n",
            "Epoch [11/50] | G Loss: 6.8452 | D Loss: 0.0007\n",
            "Epoch [12/50] | G Loss: 7.0446 | D Loss: 0.0019\n",
            "Epoch [13/50] | G Loss: 7.3296 | D Loss: 0.0006\n",
            "Epoch [14/50] | G Loss: 7.2917 | D Loss: 0.0004\n",
            "Epoch [15/50] | G Loss: 8.1754 | D Loss: 0.0002\n",
            "Epoch [16/50] | G Loss: 8.5684 | D Loss: 0.0001\n",
            "Epoch [17/50] | G Loss: 8.6007 | D Loss: 0.0001\n",
            "Epoch [18/50] | G Loss: 8.5869 | D Loss: 0.0004\n",
            "Epoch [19/50] | G Loss: 8.9012 | D Loss: 0.0001\n",
            "Epoch [20/50] | G Loss: 8.5518 | D Loss: 0.0001\n",
            "Epoch [21/50] | G Loss: 9.3223 | D Loss: 0.0001\n",
            "Epoch [22/50] | G Loss: 9.2728 | D Loss: 0.0001\n",
            "Epoch [23/50] | G Loss: 8.9224 | D Loss: 0.0001\n",
            "Epoch [24/50] | G Loss: 9.3644 | D Loss: 0.0001\n",
            "Epoch [25/50] | G Loss: 9.7291 | D Loss: 0.0000\n",
            "Epoch [26/50] | G Loss: 10.0139 | D Loss: 0.0000\n",
            "Epoch [27/50] | G Loss: 10.1574 | D Loss: 0.0000\n",
            "Epoch [28/50] | G Loss: 10.9877 | D Loss: 0.0000\n",
            "Epoch [29/50] | G Loss: 10.1487 | D Loss: 0.0000\n",
            "Epoch [30/50] | G Loss: 10.4839 | D Loss: 0.0000\n",
            "Epoch [31/50] | G Loss: 9.6895 | D Loss: 0.0000\n",
            "Epoch [32/50] | G Loss: 10.0930 | D Loss: 0.0000\n",
            "Epoch [33/50] | G Loss: 9.8801 | D Loss: 0.0000\n",
            "Epoch [34/50] | G Loss: 10.5155 | D Loss: 0.0000\n",
            "Epoch [35/50] | G Loss: 10.5922 | D Loss: 0.0000\n",
            "Epoch [36/50] | G Loss: 10.3661 | D Loss: 0.0000\n",
            "Epoch [37/50] | G Loss: 9.8278 | D Loss: 0.0000\n",
            "Epoch [38/50] | G Loss: 16.9181 | D Loss: 0.0000\n",
            "Epoch [39/50] | G Loss: 11.0370 | D Loss: 0.0000\n",
            "Epoch [40/50] | G Loss: 10.1473 | D Loss: 0.0000\n",
            "Epoch [41/50] | G Loss: 10.4663 | D Loss: 0.0000\n",
            "Epoch [42/50] | G Loss: 10.6366 | D Loss: 0.0000\n",
            "Epoch [43/50] | G Loss: 10.3993 | D Loss: 0.0000\n",
            "Epoch [44/50] | G Loss: 11.0265 | D Loss: 0.0000\n",
            "Epoch [45/50] | G Loss: 11.0927 | D Loss: 0.0000\n",
            "Epoch [46/50] | G Loss: 10.9257 | D Loss: 0.0000\n",
            "Epoch [47/50] | G Loss: 10.6450 | D Loss: 0.0000\n",
            "Epoch [48/50] | G Loss: 10.6504 | D Loss: 0.0000\n",
            "Epoch [49/50] | G Loss: 12.2855 | D Loss: 0.0000\n",
            "Epoch [50/50] | G Loss: 10.6854 | D Loss: 0.0001\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, z_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        z = self.fc2(x)\n",
        "        return z\n",
        "\n",
        "# Define the Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, z_dim, hidden_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = torch.relu(self.fc1(z))\n",
        "        x_reconstructed = torch.sigmoid(self.fc2(z))\n",
        "        return x_reconstructed\n",
        "\n",
        "# Define the Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, z_dim, hidden_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = torch.relu(self.fc1(z))\n",
        "        validity = torch.sigmoid(self.fc2(z))\n",
        "        return validity\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 28*28\n",
        "hidden_dim = 256\n",
        "z_dim = 64\n",
        "batch_size = 128\n",
        "num_epochs = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Data loading\n",
        "transform = transforms.ToTensor()\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize models\n",
        "encoder = Encoder(input_dim, hidden_dim, z_dim)\n",
        "decoder = Decoder(z_dim, hidden_dim, input_dim)\n",
        "discriminator = Discriminator(z_dim, hidden_dim)\n",
        "\n",
        "# Loss functions\n",
        "reconstruction_loss = nn.MSELoss()\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (real_data, _) in enumerate(train_loader):\n",
        "        real_data = real_data.view(-1, input_dim)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(real_data.size(0), 1)\n",
        "        fake = torch.zeros(real_data.size(0), 1)\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Encode and Decode\n",
        "        z = encoder(real_data)\n",
        "        reconstructed_data = decoder(z)\n",
        "\n",
        "        # Reconstruction loss\n",
        "        recon_loss = reconstruction_loss(reconstructed_data, real_data)\n",
        "\n",
        "        # Regularization loss\n",
        "        validity = discriminator(z)\n",
        "        reg_loss = adversarial_loss(validity, valid)\n",
        "\n",
        "        # Total loss\n",
        "        g_loss = recon_loss + reg_loss\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Sample from the prior distribution (e.g., Gaussian)\n",
        "        z_real = torch.randn(real_data.size(0), z_dim)\n",
        "        validity_real = discriminator(z_real)\n",
        "        d_real_loss = adversarial_loss(validity_real, valid)\n",
        "\n",
        "        # Discriminator loss on encoded samples\n",
        "        z_fake = encoder(real_data).detach()\n",
        "        validity_fake = discriminator(z_fake)\n",
        "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] | G Loss: {g_loss.item():.4f} | D Loss: {d_loss.item():.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ]
    }
  ]
}