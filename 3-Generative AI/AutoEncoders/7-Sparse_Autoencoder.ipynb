{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse Autoencoder Tutorial\n",
        "\n",
        "## Introduction\n",
        "\n",
        "A Sparse Autoencoder is a type of autoencoder that includes a sparsity constraint on the hidden layer. This means that the autoencoder is encouraged to learn an encoding where only a small number of neurons are active at the same time. Sparse autoencoders are useful for learning features from data, similar to how the brain operates with sparse neural activity.\n",
        "\n",
        "## Architecture\n",
        "\n",
        "A Sparse Autoencoder consists of the same parts as a regular autoencoder:\n",
        "1. **Encoder**: Compresses the input into a latent-space representation.\n",
        "2. **Decoder**: Reconstructs the input from the latent-space representation.\n",
        "\n",
        "### Encoder\n",
        "\n",
        "The encoder function, $h = f(x)$, maps the input $x$ to a hidden representation $h$. Mathematically, this can be written as:\n",
        "\n",
        "$$\n",
        "h = f(x) = \\sigma(Wx + b)\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $W$ is a weight matrix\n",
        "- $b$ is a bias vector\n",
        "- $\\sigma$ is an activation function (e.g., ReLU, sigmoid)\n",
        "\n",
        "### Decoder\n",
        "\n",
        "The decoder function, $\\hat{x} = g(h)$, maps the hidden representation $h$ back to the original input space. Mathematically, this can be written as:\n",
        "\n",
        "$$\n",
        "\\hat{x} = g(h) = \\sigma(W'h + b')\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $W'$ is a weight matrix (not necessarily the transpose of $W$)\n",
        "- $b'$ is a bias vector\n",
        "- $\\sigma$ is an activation function\n",
        "\n",
        "### Sparsity Constraint\n",
        "\n",
        "To enforce sparsity, we introduce a sparsity constraint on the hidden activations. One common approach is to enforce that the average activation of each hidden neuron is close to a small value $\\rho$. This can be achieved by adding a regularization term to the loss function. The regularization term is often based on the Kullback-Leibler (KL) divergence:\n",
        "\n",
        "$$\n",
        "KL(\\rho \\parallel \\hat{\\rho}_j) = \\rho \\log \\frac{\\rho}{\\hat{\\rho}_j} + (1 - \\rho) \\log \\frac{1 - \\rho}{1 - \\hat{\\rho}_j}\n",
        "$$\n",
        "\n",
        "where $\\rho$ is the sparsity parameter (a small value, typically 0.05), and $\\hat{\\rho}_j$ is the average activation of hidden neuron $j$ over the training set.\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "The loss function for a sparse autoencoder includes both the reconstruction error and the sparsity regularization term:\n",
        "\n",
        "$$\n",
        "L(x, \\hat{x}) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\hat{x}_i)^2 + \\beta \\sum_{j=1}^{m} KL(\\rho \\parallel \\hat{\\rho}_j)\n",
        "$$\n",
        "\n",
        "where $n$ is the number of input features, $m$ is the number of hidden neurons, and $\\beta$ is a weight that controls the importance of the sparsity term.\n",
        "\n",
        "## Training the Sparse Autoencoder\n",
        "\n",
        "Training the sparse autoencoder involves minimizing the loss function with respect to the weights and biases of the encoder and decoder. This is typically done using gradient descent.\n",
        "\n",
        "### Derivatives\n",
        "\n",
        "Let's derive the gradients for the encoder and decoder weights.\n",
        "\n",
        "#### Decoder Gradients\n",
        "\n",
        "For the decoder, the gradient of the loss function with respect to the decoder weights $W'$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W'} = \\frac{\\partial L}{\\partial \\hat{x}} \\cdot \\frac{\\partial \\hat{x}}{\\partial W'}\n",
        "$$\n",
        "\n",
        "Since $\\hat{x} = \\sigma(W'h + b')$, we have:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\hat{x}}{\\partial W'} = h \\cdot \\sigma'(W'h + b')\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W'} = (x - \\hat{x}) \\cdot \\sigma'(W'h + b') \\cdot h^T\n",
        "$$\n",
        "\n",
        "#### Encoder Gradients\n",
        "\n",
        "For the encoder, the gradient of the loss function with respect to the encoder weights $W$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial h} \\cdot \\frac{\\partial h}{\\partial W}\n",
        "$$\n",
        "\n",
        "Since $h = \\sigma(Wx + b)$ and $\\hat{\\rho}_j = \\frac{1}{N} \\sum_{i=1}^{N} h_j^{(i)}$, we have:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial h} = \\frac{\\partial L}{\\partial \\hat{x}} \\cdot \\frac{\\partial \\hat{x}}{\\partial h} + \\beta \\sum_{j=1}^{m} \\frac{\\partial KL(\\rho \\parallel \\hat{\\rho}_j)}{\\partial h}\n",
        "$$\n",
        "\n",
        "The first term is similar to the regular autoencoder:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial h} = (x - \\hat{x}) \\cdot \\sigma'(W'h + b') \\cdot W'^T\n",
        "$$\n",
        "\n",
        "The second term is the gradient of the KL divergence term:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial KL(\\rho \\parallel \\hat{\\rho}_j)}{\\partial h_j} = -\\frac{\\rho}{\\hat{\\rho}_j} + \\frac{1 - \\rho}{1 - \\hat{\\rho}_j}\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial h} = (x - \\hat{x}) \\cdot \\sigma'(W'h + b') \\cdot W'^T + \\beta \\left( -\\frac{\\rho}{\\hat{\\rho}} + \\frac{1 - \\rho}{1 - \\hat{\\rho}} \\right)\n",
        "$$\n",
        "\n",
        "And,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial h}{\\partial W} = x \\cdot \\sigma'(Wx + b)\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W} = \\left[ (x - \\hat{x}) \\cdot \\sigma'(W'h + b') \\cdot W'^T + \\beta \\left( -\\frac{\\rho}{\\hat{\\rho}} + \\frac{1 - \\rho}{1 - \\hat{\\rho}} \\right) \\right] \\cdot x^T \\cdot \\sigma'(Wx + b)\n",
        "$$\n",
        "\n",
        "### Gradient Descent Update\n",
        "\n",
        "The weights and biases are updated using the gradients:\n",
        "\n",
        "$$\n",
        "W \\leftarrow W - \\eta \\frac{\\partial L}{\\partial W}\n",
        "$$\n",
        "\n",
        "$$\n",
        "b \\leftarrow b - \\eta \\frac{\\partial L}{\\partial b}\n",
        "$$\n",
        "\n",
        "where $\\eta$ is the learning rate.\n",
        "\n",
        "##  Example\n",
        "\n",
        "Let's consider a simple  example using Python and Keras to illustrate how a sparse autoencoder works. We'll use the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8DNE53GzBhuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngs6zZruBcW-",
        "outputId": "3db27e7b-9103-4fd2-81ac-05813fea3019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "235/235 [==============================] - 8s 22ms/step - loss: 0.2596 - val_loss: 0.1757\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1559 - val_loss: 0.1392\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1318 - val_loss: 0.1225\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1185 - val_loss: 0.1120\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1090 - val_loss: 0.1042\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.1027 - val_loss: 0.0994\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0987 - val_loss: 0.0961\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0958 - val_loss: 0.0938\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0937 - val_loss: 0.0920\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0921 - val_loss: 0.0906\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0907 - val_loss: 0.0894\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0896 - val_loss: 0.0885\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0887 - val_loss: 0.0877\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0880 - val_loss: 0.0870\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0873 - val_loss: 0.0864\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0868 - val_loss: 0.0859\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0863 - val_loss: 0.0855\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0858 - val_loss: 0.0850\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0854 - val_loss: 0.0846\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0850 - val_loss: 0.0843\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0846 - val_loss: 0.0839\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0843 - val_loss: 0.0836\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0840 - val_loss: 0.0833\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0837 - val_loss: 0.0831\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0835 - val_loss: 0.0829\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0832 - val_loss: 0.0826\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0830 - val_loss: 0.0823\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0827 - val_loss: 0.0822\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0825 - val_loss: 0.0819\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0823 - val_loss: 0.0817\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0822 - val_loss: 0.0816\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0820 - val_loss: 0.0814\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0818 - val_loss: 0.0813\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0817 - val_loss: 0.0811\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0815 - val_loss: 0.0810\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0814 - val_loss: 0.0808\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0812 - val_loss: 0.0807\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0811 - val_loss: 0.0806\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0810 - val_loss: 0.0805\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0809 - val_loss: 0.0804\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0807 - val_loss: 0.0802\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0806 - val_loss: 0.0801\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0805 - val_loss: 0.0801\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0804 - val_loss: 0.0800\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0803 - val_loss: 0.0798\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0802 - val_loss: 0.0797\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0801 - val_loss: 0.0797\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0801 - val_loss: 0.0796\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0800 - val_loss: 0.0796\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0799 - val_loss: 0.0795\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Define the sparse autoencoder architecture\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(64, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# Compile the autoencoder\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Encode and decode some digits\n",
        "encoded_imgs = autoencoder.predict(x_test)\n",
        "decoded_imgs = autoencoder.predict(encoded_imgs)\n",
        "\n",
        "# Display original and reconstructed images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    }
  ]
}