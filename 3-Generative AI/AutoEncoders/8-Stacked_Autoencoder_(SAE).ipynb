{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stacked Autoencoder (SAE) Tutorial\n",
        "\n",
        "## Introduction\n",
        "\n",
        "A Stacked Autoencoder (SAE) is a deep neural network consisting of multiple layers of autoencoders stacked on top of each other. Each layer learns a compressed representation of the previous layer's output, enabling the model to learn hierarchical feature representations.\n",
        "\n",
        "## Architecture\n",
        "\n",
        "An SAE consists of multiple encoder-decoder pairs, where the output of one pair is the input to the next pair.\n",
        "\n",
        "### Encoder\n",
        "\n",
        "The encoder function for the $i$-th layer, $h_i = f_i(h_{i-1})$, maps the input $h_{i-1}$ to a hidden representation $h_i$. Mathematically, this can be written as:\n",
        "\n",
        "$$\n",
        "h_i = f_i(h_{i-1}) = \\sigma(W_i h_{i-1} + b_i)\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $W_i$ is a weight matrix for the $i$-th layer\n",
        "- $b_i$ is a bias vector for the $i$-th layer\n",
        "- $\\sigma$ is an activation function (e.g., ReLU, sigmoid)\n",
        "\n",
        "### Decoder\n",
        "\n",
        "The decoder function for the $i$-th layer, $\\hat{h}_{i-1} = g_i(h_i)$, maps the hidden representation $h_i$ back to the previous layer's space. Mathematically, this can be written as:\n",
        "\n",
        "$$\n",
        "\\hat{h}_{i-1} = g_i(h_i) = \\sigma(W_i' h_i + b_i')\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $W_i'$ is a weight matrix for the $i$-th layer\n",
        "- $b_i' is a bias vector for the $i$-th layer\n",
        "- $\\sigma$ is an activation function\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "The loss function for an SAE is typically the mean squared error (MSE) between the input and the reconstructed output for each layer:\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\hat{x}_i)^2\n",
        "$$\n",
        "\n",
        "## Training Process\n",
        "\n",
        "Training an SAE involves two main steps:\n",
        "1. **Layer-wise Pretraining**: Each layer is trained as an autoencoder to learn a compressed representation of the input.\n",
        "2. **Fine-tuning**: The entire network is trained end-to-end to minimize the reconstruction error.\n",
        "\n",
        "### Derivatives\n",
        "\n",
        "Let's derive the gradients for the encoder and decoder weights.\n",
        "\n",
        "#### Decoder Gradients\n",
        "\n",
        "For the decoder, the gradient of the loss function with respect to the decoder weights $W_i'$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W_i'} = \\frac{\\partial L}{\\partial \\hat{h}_{i-1}} \\cdot \\frac{\\partial \\hat{h}_{i-1}}{\\partial W_i'}\n",
        "$$\n",
        "\n",
        "Since $\\hat{h}_{i-1} = \\sigma(W_i' h_i + b_i')$, we have:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\hat{h}_{i-1}}{\\partial W_i'} = h_i \\cdot \\sigma'(W_i' h_i + b_i')\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W_i'} = (h_{i-1} - \\hat{h}_{i-1}) \\cdot \\sigma'(W_i' h_i + b_i') \\cdot h_i^T\n",
        "$$\n",
        "\n",
        "#### Encoder Gradients\n",
        "\n",
        "For the encoder, the gradient of the loss function with respect to the encoder weights $W_i$ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W_i} = \\frac{\\partial L}{\\partial h_i} \\cdot \\frac{\\partial h_i}{\\partial W_i}\n",
        "$$\n",
        "\n",
        "Since $h_i = \\sigma(W_i h_{i-1} + b_i)$, we have:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial h_i} = \\frac{\\partial L}{\\partial \\hat{h}_{i-1}} \\cdot \\frac{\\partial \\hat{h}_{i-1}}{\\partial h_i} = (h_{i-1} - \\hat{h}_{i-1}) \\cdot \\sigma'(W_i' h_i + b_i') \\cdot W_i'^T\n",
        "$$\n",
        "\n",
        "And,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial h_i}{\\partial W_i} = h_{i-1} \\cdot \\sigma'(W_i h_{i-1} + b_i)\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W_i} = [(h_{i-1} - \\hat{h}_{i-1}) \\cdot \\sigma'(W_i' h_i + b_i') \\cdot W_i'^T] \\cdot h_{i-1}^T \\cdot \\sigma'(W_i h_{i-1} + b_i)\n",
        "$$\n",
        "\n",
        "### Gradient Descent Update\n",
        "\n",
        "The weights and biases are updated using the gradients:\n",
        "\n",
        "$$\n",
        "W_i \\leftarrow W_i - \\eta \\frac{\\partial L}{\\partial W_i}\n",
        "$$\n",
        "\n",
        "$$\n",
        "b_i \\leftarrow b_i - \\eta \\frac{\\partial L}{\\partial b_i}\n",
        "$$\n",
        "\n",
        "where $\\eta$ is the learning rate.\n",
        "\n",
        "# Advantages and Drawbacks\n",
        "\n",
        "## Advantages\n",
        "- **Hierarchical Feature Learning**: SAEs can learn hierarchical feature representations, making them suitable for complex tasks.\n",
        "- **Improved Performance**: The deeper architecture allows the model to capture more complex patterns in the data.\n",
        "- **Layer-wise Pretraining**: Each layer can be pretrained separately, which can help with convergence and performance.\n",
        "\n",
        "## Drawbacks\n",
        "- **Increased Complexity**: The deeper architecture increases the complexity of the model, making it more computationally expensive to train.\n",
        "- **Risk of Overfitting**: The larger number of parameters increases the risk of overfitting, especially if the dataset is not sufficiently large.\n",
        "- **Training Time**: Training SAEs can be time-consuming due to the multiple layers and the need for fine-tuning.\n",
        "\n",
        "\n",
        "## Innovations and Techniques\n",
        "\n",
        "### Layer-wise Pretraining\n",
        "\n",
        "Layer-wise pretraining initializes each layer of the SAE as a separate autoencoder. This process helps in:\n",
        "- **Avoiding Vanishing Gradients**: Training each layer individually helps to avoid vanishing gradients, especially in deep networks.\n",
        "- **Initialization**: The pretraining phase initializes the weights in a way that improves convergence during fine-tuning.\n",
        "\n",
        "### Fine-tuning\n",
        "\n",
        "After layer-wise pretraining, the entire network is fine-tuned end-to-end using backpropagation to minimize the reconstruction error. Fine-tuning enables:\n",
        "- **Integration of Layers**: Fine-tuning allows the layers to work together to improve the overall reconstruction quality.\n",
        "- **Adjustment of Parameters**: Fine-tuning adjusts the weights across all layers to better capture complex patterns in the data.\n",
        "\n",
        "### Activation Functions\n",
        "\n",
        "Choosing appropriate activation functions (e.g., ReLU, sigmoid) for each layer is crucial. ReLU is commonly used in hidden layers to introduce non-linearity and accelerate convergence, while sigmoid or softmax are used in the output layer depending on the nature of the data.\n"
      ],
      "metadata": {
        "id": "fK5i-g6p0SLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "usGtKV6y0DQv",
        "outputId": "cb72617e-fe3b-44e6-e1f1-1ffe137ac1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "235/235 [==============================] - 44s 157ms/step - loss: 0.1901 - val_loss: 0.1181\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 0.1067 - val_loss: 0.0990\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 0.0932 - val_loss: 0.0887\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0871 - val_loss: 0.0852\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0836 - val_loss: 0.0816\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0811 - val_loss: 0.0802\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.0792 - val_loss: 0.0788\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0780 - val_loss: 0.0772\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0768 - val_loss: 0.0756\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0759 - val_loss: 0.0751\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.0750 - val_loss: 0.0747\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0743 - val_loss: 0.0740\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 0.0736 - val_loss: 0.0738\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0731 - val_loss: 0.0732\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0727 - val_loss: 0.0725\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 14s 60ms/step - loss: 0.0723 - val_loss: 0.0719\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.0718 - val_loss: 0.0717\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.0715 - val_loss: 0.0722\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 0.0712 - val_loss: 0.0714\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0708 - val_loss: 0.0708\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0706 - val_loss: 0.0713\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 0.0704 - val_loss: 0.0710\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 0.0702 - val_loss: 0.0701\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.0700 - val_loss: 0.0704\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 0.0698 - val_loss: 0.0697\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0696 - val_loss: 0.0706\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.0694 - val_loss: 0.0696\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0692 - val_loss: 0.0692\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 0.0691 - val_loss: 0.0690\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 0.0689 - val_loss: 0.0691\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0687 - val_loss: 0.0694\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0688 - val_loss: 0.0688\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0686 - val_loss: 0.0685\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.0684 - val_loss: 0.0688\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 14s 59ms/step - loss: 0.0684 - val_loss: 0.0685\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0682 - val_loss: 0.0691\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0681 - val_loss: 0.0681\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 11s 49ms/step - loss: 0.0681 - val_loss: 0.0683\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0680 - val_loss: 0.0682\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 0.0679 - val_loss: 0.0680\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.0678 - val_loss: 0.0679\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0677 - val_loss: 0.0679\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 0.0676 - val_loss: 0.0681\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.0676 - val_loss: 0.0680\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0675 - val_loss: 0.0676\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.0674 - val_loss: 0.0678\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 12s 52ms/step - loss: 0.0674 - val_loss: 0.0677\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.0672 - val_loss: 0.0675\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 12s 50ms/step - loss: 0.0673 - val_loss: 0.0673\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.0672 - val_loss: 0.0675\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Define the SAE architecture\n",
        "input_dim = 784\n",
        "encoding_dim1 = 512\n",
        "encoding_dim2 = 256\n",
        "encoding_dim3 = 128\n",
        "\n",
        "inputs = Input(shape=(input_dim,))\n",
        "encoded1 = Dense(encoding_dim1, activation='relu')(inputs)\n",
        "encoded2 = Dense(encoding_dim2, activation='relu')(encoded1)\n",
        "encoded3 = Dense(encoding_dim3, activation='relu')(encoded2)\n",
        "decoded3 = Dense(encoding_dim2, activation='relu')(encoded3)\n",
        "decoded2 = Dense(encoding_dim1, activation='relu')(decoded3)\n",
        "decoded1 = Dense(input_dim, activation='sigmoid')(decoded2)\n",
        "\n",
        "# Create SAE model\n",
        "autoencoder = Model(inputs, decoded1)\n",
        "autoencoder.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
        "\n",
        "# Train the SAE\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Encode and decode some digits\n",
        "encoded_imgs = autoencoder.predict(x_test)\n",
        "decoded_imgs = autoencoder.predict(encoded_imgs)\n",
        "\n",
        "# Display original and reconstructed images\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    }
  ]
}