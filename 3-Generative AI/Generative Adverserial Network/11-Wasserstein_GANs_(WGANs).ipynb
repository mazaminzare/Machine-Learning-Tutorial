{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive Tutorial on Wasserstein GANs (WGANs)\n",
        "\n",
        "Wasserstein GANs (WGANs) are an improvement over the original GAN framework introduced by Martin Arjovsky, Soumith Chintala, and LÃ©on Bottou in 2017. WGANs address several training issues of standard GANs by using the Wasserstein distance (also known as Earth Mover's distance) as the loss function.\n",
        "\n",
        "## Mathematical Foundations\n",
        "\n",
        "1. **Generator (G)**: This network takes a random noise vector $(\\mathbf{z})$ from a prior distribution $(p_{\\mathbf{z}})$ and maps it to the data space $(G(\\mathbf{z}; \\theta_G))$. The generator's objective is to generate data that resembles the true data distribution $(p_{\\text{data}})$.\n",
        "\n",
        "2. **Critic (C)**: In WGANs, the discriminator is replaced by a critic that outputs a scalar score representing the \"realness\" of the data. Unlike the original GAN discriminator, the critic does not output probabilities.\n",
        "\n",
        "The key idea is to minimize the Wasserstein distance between the real data distribution and the generated data distribution:\n",
        "$$\n",
        "W(p_{\\text{data}}, p_G) = \\inf_{\\gamma \\in \\Pi(p_{\\text{data}}, p_G)} \\mathbb{E}_{(x,y) \\sim \\gamma} [\\| x - y \\|]\n",
        "$$\n",
        "where $\\Pi(p_{\\text{data}}, p_G)$ denotes the set of all joint distributions $\\gamma(x,y)$ whose marginals are $p_{\\text{data}}$ and $p_G$ respectively.\n",
        "\n",
        "## Training Procedure\n",
        "\n",
        "The training of WGANs involves the following steps, typically repeated iteratively:\n",
        "\n",
        "1. **Sample real data** $(\\mathbf{x} \\sim p_{\\text{data}})$.\n",
        "2. **Sample noise** $(\\mathbf{z} \\sim p_{\\mathbf{z}})$ and generate fake data $(\\hat{\\mathbf{x}} = G(\\mathbf{z}))$.\n",
        "3. **Update Critic**:\n",
        "   - Compute critic loss:\n",
        "  $\n",
        "     L_C = -\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[C(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[C(G(\\mathbf{z}))]\n",
        "  $\n",
        "   - Perform a gradient descent step on $L_C$ to update $\\theta_C$.\n",
        "4. **Update Generator**:\n",
        "   - Compute generator loss:\n",
        "  $\n",
        "     L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[C(G(\\mathbf{z}))]\n",
        "  $\n",
        "   - Perform a gradient descent step on $L_G$ to update $\\theta_G$.\n",
        "\n",
        "## Mathematical Derivatives of the WGAN Training Process\n",
        "\n",
        "### Critic Training\n",
        "\n",
        "The critic aims to maximize the Wasserstein distance, which corresponds to minimizing the following loss:\n",
        "$$\n",
        "L_C = -\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[C(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[C(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "To update the critic, we compute the gradient of $L_C$ with respect to the critic's parameters $\\theta_C$:\n",
        "$$\n",
        "\\nabla_{\\theta_C} L_C = -\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}} [\\nabla_{\\theta_C} C(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} [\\nabla_{\\theta_C} C(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "### Generator Training\n",
        "\n",
        "The generator aims to minimize the critic's evaluation of the generated data:\n",
        "$$\n",
        "L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[C(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "To update the generator, we compute the gradient of $L_G$ with respect to the generator's parameters $\\theta_G$:\n",
        "$$\n",
        "\\nabla_{\\theta_G} L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} [\\nabla_{\\theta_G} C(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "### Gradient Penalty\n",
        "\n",
        "To ensure the Lipschitz constraint on the critic, WGAN-GP introduces a gradient penalty term:\n",
        "$$\n",
        "L_{\\text{GP}} = \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ (\\|\\nabla_{\\hat{\\mathbf{x}}} C(\\hat{\\mathbf{x}})\\|_2 - 1)^2 \\right]\n",
        "$$\n",
        "where $\\hat{\\mathbf{x}}$ is sampled uniformly along straight lines between pairs of points from the real data and the generated data distributions.\n",
        "\n",
        "### Training Procedure with Gradient Penalty\n",
        "\n",
        "The training procedure of WGANs with the gradient penalty term is as follows:\n",
        "\n",
        "1. **Critic Update**:\n",
        "    - Sample real data $(\\mathbf{x} \\sim p_{\\text{data}})$.\n",
        "    - Sample noise $(\\mathbf{z} \\sim p_{\\mathbf{z}})$ and generate fake data $(\\hat{\\mathbf{x}} = G(\\mathbf{z}))$.\n",
        "    - Sample $\\hat{\\mathbf{x}}$ uniformly along straight lines between $\\mathbf{x}$ and $\\hat{\\mathbf{x}}$.\n",
        "    - Compute the critic loss with the gradient penalty:\n",
        "  $\n",
        "      L_C = -\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}} [C(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} [C(G(\\mathbf{z}))] + \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ (\\|\\nabla_{\\hat{\\mathbf{x}}} C(\\hat{\\mathbf{x}})\\|_2 - 1)^2 \\right]\n",
        "  $\n",
        "    - Compute gradients:\n",
        "  $\n",
        "      \\nabla_{\\theta_C} L_C = -\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}} [\\nabla_{\\theta_C} C(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} [\\nabla_{\\theta_C} C(G(\\mathbf{z}))] + \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ 2 (\\|\\nabla_{\\hat{\\mathbf{x}}} C(\\hat{\\mathbf{x}})\\|_2 - 1) \\nabla_{\\theta_C} \\|\\nabla_{\\hat{\\mathbf{x}}} C(\\hat{\\mathbf{x}})\\|_2 \\right]\n",
        "  $\n",
        "    - Update $\\theta_C$ using gradient descent.\n",
        "\n",
        "2. **Generator Update**:\n",
        "    - Sample noise $(\\mathbf{z} \\sim p_{\\mathbf{z}})$.\n",
        "    - Generate fake data $(\\hat{\\mathbf{x}} = G(\\mathbf{z}))$.\n",
        "    - Compute the generator loss:\n",
        "  $\n",
        "      L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[C(\\hat{\\mathbf{x}})]\n",
        "  $\n",
        "    - Compute gradients:\n",
        "  $\n",
        "      \\nabla_{\\theta_G} L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} [\\nabla_{\\theta_G} C(\\hat{\\mathbf{x}})]\n",
        "  $\n",
        "    - Update $\\theta_G$ using gradient descent.\n",
        "\n",
        "## Key Innovations\n",
        "\n",
        "1. **Wasserstein Distance**: The use of the Wasserstein distance provides a smoother and more meaningful loss metric compared to the Jensen-Shannon divergence used in standard GANs.\n",
        "2. **Lipschitz Constraint**: The enforcement of the Lipschitz constraint on the critic ensures more stable training and addresses gradient issues.\n",
        "3. **Gradient Penalty**: The gradient penalty term provides a practical way to enforce the Lipschitz constraint without clipping weights, leading to better performance.\n",
        "\n",
        "## Advantages of WGANs\n",
        "\n",
        "1. **Improved Training Stability**: WGANs are more stable to train and less sensitive to hyperparameter choices compared to standard GANs.\n",
        "2. **Meaningful Loss Metric**: The Wasserstein distance offers a meaningful loss metric that correlates better with the quality of generated samples.\n",
        "3. **No Mode Collapse**: WGANs are less prone to mode collapse, where the generator produces limited varieties of samples.\n",
        "\n",
        "## Drawbacks of WGANs\n",
        "\n",
        "1. **Increased Computational Cost**: The gradient penalty term and the need for more critic updates per generator update increase the computational cost.\n",
        "2. **Sensitive to Critic Capacity**: The performance of WGANs can be sensitive to the capacity and architecture of the critic network.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Wasserstein GANs (WGANs) have significantly improved the stability and performance of GAN training by using the Wasserstein distance and enforcing the Lipschitz constraint on the critic. Understanding the mathematical foundations and training dynamics of WGANs, including the derivatives of the training process and the gradient penalty term, is crucial for leveraging their full potential and addressing their limitations.\n"
      ],
      "metadata": {
        "id": "d1qrw7PZRzHK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsDXvnB2Ryjq"
      },
      "outputs": [],
      "source": []
    }
  ]
}