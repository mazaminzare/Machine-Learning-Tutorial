{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive Tutorial on WGAN-GP (Wasserstein GAN with Gradient Penalty)\n",
        "\n",
        "Wasserstein GAN with Gradient Penalty (WGAN-GP) is an improved version of the original GAN framework designed to address some of the training difficulties, such as mode collapse and instability. WGAN-GP uses the Wasserstein distance (also known as the Earth Mover's distance) as a metric to measure the distance between the real data distribution and the generated data distribution. Additionally, it employs a gradient penalty to enforce the Lipschitz constraint.\n",
        "\n",
        "## Mathematical Foundations\n",
        "\n",
        "1. **Generator (G)**: This network takes a random noise vector $(\\mathbf{z})$ from a prior distribution $(p_{\\mathbf{z}})$ (often a Gaussian or uniform distribution) and maps it to the data space $(G(\\mathbf{z}; \\theta_G))$. The generator's objective is to generate data that resembles the true data distribution $(p_{\\text{data}})$.\n",
        "\n",
        "2. **Discriminator (D)** (often called the critic in WGANs): This network takes a data sample (either real or generated) and outputs a scalar value representing the \"realness\" of the sample.\n",
        "\n",
        "The WGAN objective function replaces the traditional GAN's cross-entropy loss with the Wasserstein distance:\n",
        "$$\n",
        "\\min_G \\max_D V(D, G) = \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[D(\\mathbf{x})] - \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "### Gradient Penalty\n",
        "\n",
        "To enforce the Lipschitz constraint, WGAN-GP adds a gradient penalty term to the discriminator's loss. The gradient penalty ensures that the gradient of the discriminator's output with respect to its input has a norm of at most 1.\n",
        "\n",
        "The gradient penalty term is defined as:\n",
        "$$\n",
        "\\text{GP} = \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ (\\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 - 1)^2 \\right]\n",
        "$$\n",
        "where $\\lambda$ is the penalty coefficient and $\\hat{\\mathbf{x}}$ is sampled uniformly along straight lines between pairs of points from the real data distribution and the generated data distribution.\n",
        "\n",
        "## Training Procedure\n",
        "\n",
        "The training of WGAN-GP involves the following steps, typically repeated iteratively:\n",
        "\n",
        "1. **Sample real data** $(\\mathbf{x} \\sim p_{\\text{data}})$.\n",
        "2. **Sample noise** $(\\mathbf{z} \\sim p_{\\mathbf{z}})$ and generate fake data $(\\hat{\\mathbf{x}} = G(\\mathbf{z}))$.\n",
        "3. **Sample interpolates** $\\hat{\\mathbf{x}} = \\epsilon \\mathbf{x} + (1 - \\epsilon) \\hat{\\mathbf{x}}$ where $\\epsilon \\sim U[0, 1]$.\n",
        "4. **Update Discriminator**:\n",
        "   - Compute discriminator loss with gradient penalty:\n",
        "  $\n",
        "     L_D = -\\left(\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[D(\\mathbf{x})] - \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(G(\\mathbf{z}))]\\right) + \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ (\\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 - 1)^2 \\right]\n",
        "  $\n",
        "   - Perform a gradient descent step on $L_D$ to update $\\theta_D$.\n",
        "5. **Update Generator**:\n",
        "   - Compute generator loss:\n",
        "  $\n",
        "     L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(G(\\mathbf{z}))]\n",
        "  $\n",
        "   - Perform a gradient descent step on $L_G$ to update $\\theta_G$.\n",
        "\n",
        "## Mathematical Derivatives of the WGAN-GP Training Process\n",
        "\n",
        "### Discriminator Training\n",
        "\n",
        "The discriminator aims to maximize the difference between the expected value of the real samples and the generated samples, with an additional gradient penalty term to enforce the Lipschitz constraint.\n",
        "\n",
        "The loss function for the discriminator is:\n",
        "$$\n",
        "L_D = -\\left( \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[D(\\mathbf{x})] - \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(G(\\mathbf{z}))] \\right) + \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ (\\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 - 1)^2 \\right]\n",
        "$$\n",
        "\n",
        "To update the discriminator, we compute the gradient of $L_D$ with respect to the discriminator's parameters $\\theta_D$:\n",
        "$$\n",
        "\\nabla_{\\theta_D} L_D = -\\left( \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[\\nabla_{\\theta_D} D(\\mathbf{x})] - \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[\\nabla_{\\theta_D} D(G(\\mathbf{z}))] \\right) + \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ 2(\\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 - 1) \\nabla_{\\theta_D} \\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 \\right]\n",
        "$$\n",
        "\n",
        "### Generator Training\n",
        "\n",
        "The generator aims to maximize the discriminator's output for the generated samples, effectively minimizing the Wasserstein distance between the real and generated data distributions.\n",
        "\n",
        "The loss function for the generator is:\n",
        "$$\n",
        "L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "To update the generator, we compute the gradient of $L_G$ with respect to the generator's parameters $\\theta_G$:\n",
        "$$\n",
        "\\ \\nabla_{\\theta_G} L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} [\\nabla_{\\theta_G} D(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "### Training Procedure with Gradients\n",
        "\n",
        "The training procedure of WGAN-GP with the detailed gradient steps is as follows:\n",
        "\n",
        "1. **Discriminator Update**:\n",
        "    - Sample real data $(\\mathbf{x} \\sim p_{\\text{data}})$.\n",
        "    - Sample noise $(\\mathbf{z} \\sim p_{\\mathbf{z}})$ and generate fake data $(\\hat{\\mathbf{x}} = G(\\mathbf{z}))$.\n",
        "    - Sample interpolates $\\hat{\\mathbf{x}} = \\epsilon \\mathbf{x} + (1 - \\epsilon) \\hat{\\mathbf{x}}$ where $\\epsilon \\sim U[0, 1]$.\n",
        "    - Compute the discriminator loss with gradient penalty:\n",
        "  $\n",
        "      L_D = -\\left( \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[D(\\mathbf{x})] - \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(\\hat{\\mathbf{x}})] \\right) + \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ (\\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 - 1)^2 \\right]\n",
        "  $\n",
        "    - Compute gradients:\n",
        "  $\n",
        "      \\nabla_{\\theta_D} L_D = -\\left( \\nabla_{\\theta_D} \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}} [D(\\mathbf{x})] - \\nabla_{\\theta_D} \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(G(\\mathbf{z}))] \\right) + \\lambda \\mathbb{E}_{\\hat{\\mathbf{x}} \\sim p_{\\hat{\\mathbf{x}}}} \\left[ 2(\\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 - 1) \\nabla_{\\theta_D} \\|\\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}})\\|_2 \\right]\n",
        "  $\n",
        "    - Update $\\theta_D$ using gradient descent.\n",
        "\n",
        "2. **Generator Update**:\n",
        "    - Sample noise $(\\mathbf{z} \\sim p_{\\mathbf{z}})$.\n",
        "    - Generate fake data $(\\hat{\\mathbf{x}} = G(\\mathbf{z}))$.\n",
        "    - Compute the generator loss:\n",
        "  $\n",
        "      L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[D(\\hat{\\mathbf{x}})]\n",
        "  $\n",
        "    - Compute gradients:\n",
        "  $\n",
        "      \\nabla_{\\theta_G} L_G = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} [\\nabla_{\\theta_G} D(\\hat{\\mathbf{x}})]\n",
        "  $\n",
        "    - Update $\\theta_G$ using gradient descent.\n",
        "\n",
        "## Key Innovations\n",
        "\n",
        "1. **Wasserstein Distance**: The use of the Wasserstein distance provides a smoother and more stable training process.\n",
        "2. **Gradient Penalty**: The gradient penalty enforces the Lipschitz constraint without requiring weight clipping, improving training stability and performance.\n",
        "\n",
        "## Advantages of WGAN-GP\n",
        "\n",
        "1. **Improved Training Stability**: The use of the Wasserstein distance and gradient penalty results in more stable training compared to original GANs.\n",
        "2. **Better Mode Coverage**: WGAN-GP helps mitigate mode collapse, generating a more diverse set of samples.\n",
        "3. **Consistent Loss Metric**: The loss metric in WGAN-GP correlates well with the quality of generated samples, providing a more meaningful measure of progress during training.\n",
        "\n",
        "## Drawbacks of WGAN-GP\n",
        "\n",
        "1. **Computationally Intensive**: The gradient penalty term requires additional computation, making WGAN-GP more computationally intensive than traditional GANs.\n",
        "2. **Sensitive to Hyperparameters**: The choice of the gradient penalty coefficient $\\lambda$ and other hyperparameters can significantly affect performance.\n",
        "3. **Implementation Complexity**: Implementing the gradient penalty and ensuring stable training can be more complex than traditional GANs.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "WGAN-GP addresses several key challenges in training GANs by using the Wasserstein distance and gradient penalty. These innovations result in more stable training and better-quality generated samples. Understanding the mathematical foundations and training dynamics of WGAN-GP, including the derivatives of the training process and improved loss functions, is crucial for leveraging their full potential and addressing their limitations.\n"
      ],
      "metadata": {
        "id": "gztnj3YVYm3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "algZdTN0YlYA"
      },
      "outputs": [],
      "source": []
    }
  ]
}