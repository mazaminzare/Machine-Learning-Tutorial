{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive Tutorial on SRGAN (Super-Resolution GAN)\n",
        "\n",
        "Super-Resolution GAN (SRGAN) is a type of Generative Adversarial Network (GAN) designed for image super-resolution. It was introduced by Christian Ledig et al. in 2017 to generate high-resolution images from low-resolution inputs.\n",
        "\n",
        "## Mathematical Foundations\n",
        "\n",
        "1. **Generator (G)**: The generator in SRGAN takes a low-resolution image $(\\mathbf{I}^{LR})$ and generates a high-resolution image $(\\mathbf{I}^{SR})$:\n",
        "   $$\n",
        "   \\mathbf{I}^{SR} = G(\\mathbf{I}^{LR}; \\theta_G)\n",
        "   $$\n",
        "\n",
        "2. **Discriminator (D)**: The discriminator takes an image (either real high-resolution or generated) and outputs a probability that the image is real:\n",
        "   $$\n",
        "   D(\\mathbf{I}; \\theta_D)\n",
        "   $$\n",
        "\n",
        "The SRGAN is trained with two loss functions:\n",
        "- Adversarial Loss: Encourages the generator to produce images indistinguishable from real high-resolution images.\n",
        "- Content Loss: Ensures the generated images are perceptually similar to the real images.\n",
        "\n",
        "### Adversarial Loss\n",
        "\n",
        "The adversarial loss is similar to the original GAN formulation:\n",
        "$$\n",
        "\\min_G \\max_D V(D, G) = \\mathbb{E}_{\\mathbf{I}^{HR} \\sim p_{\\text{data}}}[\\log D(\\mathbf{I}^{HR})] + \\mathbb{E}_{\\mathbf{I}^{LR} \\sim p_{\\mathbf{I}^{LR}}}[\\log (1 - D(G(\\mathbf{I}^{LR})))]\n",
        "$$\n",
        "\n",
        "### Content Loss\n",
        "\n",
        "The content loss is often defined using a combination of pixel-wise MSE loss and perceptual loss. The perceptual loss is computed using a pre-trained VGG network:\n",
        "$$\n",
        "L_{\\text{content}} = \\mathbb{E} \\left[ \\| \\phi(\\mathbf{I}^{HR}) - \\phi(\\mathbf{I}^{SR}) \\|_2^2 \\right]\n",
        "$$\n",
        "where $\\phi$ represents the feature maps obtained from a specific layer of the VGG network.\n",
        "\n",
        "The final generator loss combines the content loss and the adversarial loss:\n",
        "$$\n",
        "L_G = L_{\\text{content}} + 10^{-3} \\cdot L_{\\text{adv}}\n",
        "$$\n",
        "\n",
        "## Training Procedure\n",
        "\n",
        "The training of SRGAN involves the following steps, typically repeated iteratively:\n",
        "\n",
        "1. **Sample real high-resolution images** $(\\mathbf{I}^{HR} \\sim p_{\\text{data}})$.\n",
        "2. **Generate low-resolution images** $(\\mathbf{I}^{LR})$ by downsampling $\\mathbf{I}^{HR}$.\n",
        "3. **Generate super-resolved images** $(\\mathbf{I}^{SR} = G(\\mathbf{I}^{LR}))$.\n",
        "\n",
        "### Discriminator Update\n",
        "\n",
        "4. **Compute discriminator loss**:\n",
        "$\n",
        "   L_D = -\\left( \\mathbb{E}_{\\mathbf{I}^{HR} \\sim p_{\\text{data}}}[\\log D(\\mathbf{I}^{HR})] + \\mathbb{E}_{\\mathbf{I}^{LR} \\sim p_{\\mathbf{I}^{LR}}}[\\log (1 - D(G(\\mathbf{I}^{LR})))] \\right)\n",
        "$\n",
        "5. **Perform a gradient descent step on $L_D$ to update $\\theta_D$**.\n",
        "\n",
        "### Generator Update\n",
        "\n",
        "6. **Compute generator loss**:\n",
        "   $$\n",
        "   L_G = \\mathbb{E} \\left[ \\| \\phi(\\mathbf{I}^{HR}) - \\phi(\\mathbf{I}^{SR}) \\|_2^2 \\right] + 10^{-3} \\cdot \\left( -\\mathbb{E}_{\\mathbf{I}^{LR} \\sim p_{\\mathbf{I}^{LR}}}[\\log D(G(\\mathbf{I}^{LR}))] \\right)\n",
        "   $$\n",
        "7. **Perform a gradient descent step on $L_G$ to update $\\theta_G$**.\n",
        "\n",
        "## Key Innovations\n",
        "\n",
        "1. **Perceptual Loss**: The use of perceptual loss ensures that the generated high-resolution images are perceptually similar to the ground truth.\n",
        "2. **Adversarial Training**: The adversarial loss helps generate sharper and more realistic images compared to traditional methods.\n",
        "3. **VGG-based Content Loss**: The content loss based on VGG network features helps in preserving high-level content in the images.\n",
        "\n",
        "## Advantages of SRGAN\n",
        "\n",
        "1. **High-Quality Super-Resolution**: SRGAN produces high-resolution images that are sharper and more realistic than traditional methods.\n",
        "2. **Preservation of High-Level Features**: The use of VGG-based content loss helps in maintaining the perceptual quality of images.\n",
        "3. **Versatility**: SRGAN can be applied to various image super-resolution tasks, including upscaling low-resolution images from different domains.\n",
        "\n",
        "## Drawbacks of SRGAN\n",
        "\n",
        "1. **Training Instability**: Similar to other GANs, SRGAN can suffer from training instability and mode collapse.\n",
        "2. **Sensitive to Hyperparameters**: The performance of SRGAN is highly dependent on the choice of hyperparameters and network architecture.\n",
        "3. **Computationally Intensive**: Training SRGAN requires significant computational resources and time.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "SRGAN represents a significant advancement in the field of image super-resolution by leveraging the power of GANs and perceptual loss. Understanding the mathematical foundations and training dynamics of SRGAN, including the derivatives of the training process and improved loss functions, is crucial for leveraging their full potential and addressing their limitations. Despite the challenges, SRGAN continues to drive progress in generating high-quality super-resolved images, making it a valuable tool in various applications.\n"
      ],
      "metadata": {
        "id": "3gSnb3K1lZ45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEAhydi1lZfi"
      },
      "outputs": [],
      "source": []
    }
  ]
}