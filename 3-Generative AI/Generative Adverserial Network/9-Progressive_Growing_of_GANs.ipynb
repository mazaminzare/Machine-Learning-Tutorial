{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive Tutorial on Progressive Growing of GANs (ProGAN)\n",
        "\n",
        "Progressive Growing of GANs (ProGAN) is an advanced technique introduced by Karras et al. in 2017 to improve the stability and quality of GAN training, especially for generating high-resolution images. ProGANs start with low-resolution images and progressively increase the resolution by adding layers to the generator and discriminator networks.\n",
        "\n",
        "## Mathematical Foundations\n",
        "\n",
        "### Generator (G)\n",
        "\n",
        "The generator takes a random noise vector $(\\mathbf{z})$ from a prior distribution $(p_{\\mathbf{z}})$ (often a Gaussian or uniform distribution) and maps it to the data space $(G(\\mathbf{z}; \\theta_G))$. In ProGAN, the generator starts with a low-resolution image and progressively increases the resolution.\n",
        "\n",
        "### Discriminator (D)\n",
        "\n",
        "The discriminator takes a data sample (either real or generated) and outputs a single scalar $(D(\\mathbf{x}; \\theta_D))$ representing the probability that the sample is real. The discriminator in ProGAN also starts with low-resolution images and progressively increases the resolution.\n",
        "\n",
        "The networks are trained with the following min-max objective function:\n",
        "$$\n",
        "\\min_G \\max_D V(D, G) = \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[\\log (1 - D(G(\\mathbf{z})))]\n",
        "$$\n",
        "\n",
        "## Training Procedure\n",
        "\n",
        "The training of ProGANs involves the following steps, typically repeated iteratively:\n",
        "\n",
        "1. **Initialize with Low Resolution**: Start with a low-resolution generator and discriminator.\n",
        "2. **Progressively Increase Resolution**: Gradually add layers to both the generator and discriminator to increase the resolution of generated images.\n",
        "3. **Fade-in Transition**: Use a fade-in mechanism to smoothly transition between resolutions.\n",
        "\n",
        "### Training Steps\n",
        "\n",
        "1. **Sample real data** $(\\mathbf{x} \\sim p_{\\text{data}})$.\n",
        "2. **Sample noise** $(\\mathbf{z} \\sim p_{\\mathbf{z}})$ and generate fake data $(\\hat{\\mathbf{x}} = G(\\mathbf{z}))$.\n",
        "3. **Update Discriminator**:\n",
        "   - Compute discriminator loss:\n",
        "  $\n",
        "     L_D = -\\left(\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[\\log (1 - D(G(\\mathbf{z})))]\\right)\n",
        "  $\n",
        "   - Perform a gradient descent step on $L_D$ to update $\\theta_D$.\n",
        "4. **Update Generator**:\n",
        "   - Compute generator loss using the non-saturating loss:\n",
        "  $\n",
        "     L_G' = -\\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[\\log D(G(\\mathbf{z}))]\n",
        "  $\n",
        "   - Perform a gradient descent step on $L_G'$ to update $\\theta_G$.\n",
        "\n",
        "### Mathematical Derivatives of the GAN Training Process\n",
        "\n",
        "To delve deeper into the training process of ProGANs, we need to examine the mathematical derivatives that guide the optimization of both the generator and the discriminator.\n",
        "\n",
        "#### Discriminator Training\n",
        "\n",
        "The discriminator aims to maximize the probability of correctly classifying real and generated samples. The loss function for the discriminator is:\n",
        "$$\n",
        "L_D = -\\left( \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}}[\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[\\log (1 - D(G(\\mathbf{z})))] \\right)\n",
        "$$\n",
        "\n",
        "To update the discriminator, we compute the gradient of $L_D$ with respect to the discriminator's parameters $\\theta_D$:\n",
        "$$\n",
        "\\nabla_{\\theta_D} L_D = -\\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}} \\left[ \\frac{1}{D(\\mathbf{x})} \\nabla_{\\theta_D} D(\\mathbf{x}) \\right] - \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} \\left[ \\frac{1}{1 - D(G(\\mathbf{z}))} \\nabla_{\\theta_D} D(G(\\mathbf{z})) \\right]\n",
        "$$\n",
        "\n",
        "#### Generator Training\n",
        "\n",
        "The generator aims to fool the discriminator, which can be framed as maximizing the following objective:\n",
        "$$\n",
        "L_G' = \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}[\\log D(G(\\mathbf{z}))]\n",
        "$$\n",
        "\n",
        "To update the generator, we compute the gradient of $L_G'$ with respect to the generator's parameters $\\theta_G$:\n",
        "$$\n",
        "\\nabla_{\\theta_G} L_G' = \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} \\left[ \\frac{1}{D(G(\\mathbf{z}))} \\nabla_{\\theta_G} D(G(\\mathbf{z})) \\right]\n",
        "$$\n",
        "\n",
        "### Progressive Growing\n",
        "\n",
        "ProGANs improve the quality of GAN training by progressively growing the network:\n",
        "\n",
        "1. **Start with Low Resolution**: Begin training with a low-resolution generator and discriminator, such as 4x4 pixels.\n",
        "2. **Incrementally Add Layers**: Gradually increase the resolution by adding new layers to both the generator and discriminator.\n",
        "3. **Fade-in Mechanism**: Smoothly transition between resolutions using a fade-in mechanism. During the fade-in, the output of the new higher-resolution layer is blended with the output of the previous lower-resolution layer.\n",
        "\n",
        "## Key Innovations\n",
        "\n",
        "1. **Progressive Growing**: The key innovation of ProGAN is the progressive growing of the generator and discriminator, which stabilizes training and improves image quality.\n",
        "2. **Fade-in Transition**: The fade-in mechanism helps in smooth transitioning between different resolutions, reducing artifacts and improving stability.\n",
        "3. **Equalized Learning Rate**: Normalizes the learning rate for each layer based on its dynamic range, leading to more stable training.\n",
        "4. **Pixelwise Feature Vector Normalization**: Normalizes feature vectors in each pixel to have unit length, enhancing the stability of training.\n",
        "\n",
        "## Advantages of ProGANs\n",
        "\n",
        "1. **High-Quality High-Resolution Images**: ProGANs can generate highly realistic high-resolution images.\n",
        "2. **Stable Training**: The progressive growing technique improves the stability of GAN training, reducing common issues like mode collapse and oscillations.\n",
        "3. **Efficient Training**: Starting with low resolution and gradually increasing it makes the training process more efficient and manageable.\n",
        "\n",
        "## Drawbacks of ProGANs\n",
        "\n",
        "1. **Complex Implementation**: The progressive growing technique and fade-in transition require careful implementation and tuning.\n",
        "2. **Longer Training Time**: The process of gradually increasing resolution can result in longer training times compared to standard GANs.\n",
        "3. **Sensitive to Hyperparameters**: The performance of ProGANs can be sensitive to the choice of hyperparameters and the architecture of the network.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "ProGANs have significantly advanced the field of generative modeling by introducing techniques to stabilize training and improve the quality of generated images, particularly at high resolutions. Understanding the mathematical foundations, training procedures, and innovative techniques of ProGANs is essential for leveraging their full potential in various applications. Despite the challenges, ProGANs remain a powerful tool for generating realistic data and have inspired further research and development in the field of GANs.\n"
      ],
      "metadata": {
        "id": "kqPuX42Ca4cp"
      }
    }
  ]
}