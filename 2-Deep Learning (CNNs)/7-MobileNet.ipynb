{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive MobileNet Tutorial with Detailed Mathematical Formulations\n",
        "\n",
        "MobileNet is a family of efficient convolutional neural network architectures designed for mobile and embedded vision applications. This tutorial provides a detailed mathematical breakdown of MobileNet operations, including forward and backward passes for each layer.\n",
        "\n",
        "## MobileNet Architecture Overview\n",
        "\n",
        "MobileNet uses depthwise separable convolutions to build lightweight deep neural networks. Key components include:\n",
        "\n",
        "1. **Input Layer**: Processes the input image.\n",
        "2. **Standard Convolution Layer**: Initial convolution layer.\n",
        "3. **Depthwise Separable Convolutions**: Consist of depthwise and pointwise convolutions.\n",
        "4. **Fully Connected Output Layer**: Produces the classification output.\n",
        "5. **Output Layer**: Applies a softmax function for classification.\n",
        "\n",
        "### Initial Convolution Layer\n",
        "- **Forward Pass**:\n",
        "  - **Formula**: $O = \\sigma(W \\ast X + b)$\n",
        "    - Where $\\ast$ denotes the convolution operation.\n",
        "- **Backward Pass**:\n",
        "  - **Gradient w.r.t. input**: $\\frac{\\partial L}{\\partial X} = W^T \\ast \\frac{\\partial L}{\\partial O} \\cdot \\sigma'(W \\ast X + b)$\n",
        "  - **Gradient w.r.t. weights**: $\\frac{\\partial L}{\\partial W} = X \\ast \\frac{\\partial L}{\\partial O} \\cdot \\sigma'(W \\ast X + b)$\n",
        "\n",
        "### Depthwise Separable Convolution\n",
        "Depthwise separable convolutions consist of a depthwise convolution followed by a pointwise convolution.\n",
        "\n",
        "#### Depthwise Convolution\n",
        "- **Forward Pass**:\n",
        "  - **Formula**: $d_{ijk} = \\sigma(\\sum_{m=0}^{M-1} W_{mjk} \\ast X_{i+m, j+m, k} + b_k)$\n",
        "    - Where the convolution is applied to each input channel separately.\n",
        "- **Backward Pass**:\n",
        "  - **Gradient w.r.t. input**: $\\frac{\\partial L}{\\partial X_{i+m, j+m, k}} = \\sum_{m=0}^{M-1} W_{mjk}^T \\ast \\frac{\\partial L}{\\partial d_{ijk}} \\cdot \\sigma'(\\sum_{m=0}^{M-1} W_{mjk} \\ast X_{i+m, j+m, k} + b_k)$\n",
        "  - **Gradient w.r.t. weights**: $\\frac{\\partial L}{\\partial W_{mjk}} = X_{i+m, j+m, k} \\ast \\frac{\\partial L}{\\partial d_{ijk}} \\cdot \\sigma'(\\sum_{m=0}^{M-1} W_{mjk} \\ast X_{i+m, j+m, k} + b_k)$\n",
        "\n",
        "#### Pointwise Convolution\n",
        "- **Forward Pass**:\n",
        "  - **Formula**: $p_{ijk} = \\sigma(\\sum_{c=0}^{C-1} W_{kc} \\ast d_{ijc} + b_k)$\n",
        "- **Backward Pass**:\n",
        "  - **Gradient w.r.t. input**: $\\frac{\\partial L}{\\partial d_{ijc}} = \\sum_{k=0}^{K-1} W_{kc}^T \\ast \\frac{\\partial L}{\\partial p_{ijk}} \\cdot \\sigma'(\\sum_{c=0}^{C-1} W_{kc} \\ast d_{ijc} + b_k)$\n",
        "  - **Gradient w.r.t. weights**: $\\frac{\\partial L}{\\partial W_{kc}} = d_{ijc} \\ast \\frac{\\partial L}{\\partial p_{ijk}} \\cdot \\sigma'(\\sum_{c=0}^{C-1} W_{kc} \\ast d_{ijc} + b_k)$\n",
        "\n",
        "### Fully Connected Layers\n",
        "- **Forward Pass**:\n",
        "  - **Formula**: $O = W \\cdot x + b$\n",
        "- **Backward Pass**:\n",
        "  - **Gradient w.r.t. input**: $\\frac{\\partial L}{\\partial x} = W^T \\cdot \\frac{\\partial L}{\\partial O}$\n",
        "  - **Gradient w.r.t. weights**: $\\frac{\\partial L}{\\partial W} = x \\cdot \\frac{\\partial L}{\\partial O}$\n",
        "\n",
        "### Global Average Pooling\n",
        "- **Forward Pass**:\n",
        "  - **Formula**: $O_k = \\frac{1}{H \\times W} \\sum_{i=1}^H \\sum_{j=1}^W x_{ijk}$\n",
        "- **Backward Pass**:\n",
        "  - **Gradient w.r.t. input**: $\\frac{\\partial L}{\\partial x_{ijk}} = \\frac{1}{H \\times W} \\frac{\\partial L}{\\partial O_k}$\n",
        "\n",
        "### Output Layer - Softmax\n",
        "- **Forward Pass**:\n",
        "  - **Formula**: $S_k = \\frac{e^{O_k}}{\\sum_i e^{O_i}}$\n",
        "- **Backward Pass**:\n",
        "  - **Gradient w.r.t. output of last fully connected layer**: $\\frac{\\partial L}{\\partial O_k} = S_k - y_k$, where $y_k$ is the target class.\n",
        "\n"
      ],
      "metadata": {
        "id": "ULyhMDub-G_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileNet Overview\n",
        "\n",
        "MobileNet, developed by Google researchers, is designed to bring powerful computer vision models to mobile devices by optimizing the balance between latency, size, and accuracy. Introduced in several versions with incremental improvements, MobileNet uses depthwise separable convolutions as the fundamental building block, significantly reducing the computational cost and model size.\n",
        "\n",
        "### Key Innovations of MobileNet\n",
        "\n",
        "MobileNet has introduced significant improvements in model design tailored for mobile devices:\n",
        "\n",
        "1. **Depthwise Separable Convolutions**: This technique splits the convolution into a depthwise convolution and a 1x1 pointwise convolution, reducing computational complexity and model size dramatically.\n",
        "2. **Width Multiplier**: A hyperparameter that allows the model builder to thin a network uniformly at each layer, for a good trade-off between latency and accuracy.\n",
        "3. **Resolution Multiplier**: Adjusts the input resolution of the image, allowing further reduction in computational demand without extensive retraining or architecture changes.\n",
        "\n",
        "### Variants of MobileNet\n",
        "\n",
        "MobileNet has been developed in several variants, each optimizing different aspects of the model:\n",
        "\n",
        "- **MobileNetV1**: The original version, focusing on depthwise separable convolutions to reduce model size and complexity.\n",
        "- **MobileNetV2**: Introduces inverted residuals and linear bottlenecks that capture more complex features and allow for reduced parameter count and increased performance.\n",
        "- **MobileNetV3**: Applies lessons from AutoML and network design to optimize efficiency; introduces new components like the squeeze-and-excitation blocks.\n",
        "\n",
        "### Detailed Architecture and Parameters\n",
        "\n",
        "Here's an overview of the general structure of MobileNetV1:\n",
        "\n",
        "| Layer Type                | Input Dimension              | Output Dimension             | Kernel Size/Stride/Pad | Parameters Formula                                              | Number of Parameters |\n",
        "|---------------------------|------------------------------|------------------------------|------------------------|-----------------------------------------------------------------|----------------------|\n",
        "| **Input**                 | $224 \\times 224 \\times 3$    | N/A                          | N/A                    | N/A                                                             | 0                    |\n",
        "| **Conv DW**               | $224 \\times 224 \\times 3$    | $112 \\times 112 \\times 32$   | $3 \\times 3$, S=2, P=1 | Depthwise: $(3 \\times 3 \\times 32) \\times 1$                    | 288                  |\n",
        "| **Conv PW**               | $112 \\times 112 \\times 32$   | $112 \\times 112 \\times 64$   | $1 \\times 1$, S=1, P=0 | Pointwise: $(1 \\times 1 \\times 32) \\times 64$                   | 2,048                |\n",
        "| **Conv DW**               | $112 \\times 112 \\times 64$   | $56 \\times 56 \\times 64$     | $3 \\times 3$, S=2, P=1 | Depthwise: $(3 \\times 3 \\times 64) \\times 1$                    | 576                  |\n",
        "| **Global Avg Pooling**    | $7 \\times 7 \\times 1024$     | $1 \\times 1 \\times 1024$     | Global                 | 0                                                               | 0                    |\n",
        "| **Fully Connected**       | $1024$                       | Number of classes            | N/A                    | $(1024 + 1) \\times \\text{Number of classes}$                    | Varies               |\n",
        "\n",
        "### Advantages of MobileNet\n",
        "\n",
        "- **High Efficiency**: Extremely lightweight architecture makes it suitable for mobile devices with limited computational resources.\n",
        "- **Versatility**: Can be easily adapted for a wide range of applications beyond image classification, including object detection and facial recognition.\n",
        "- **Customizable**: Width and resolution multipliers allow developers to balance between latency, accuracy, and size based on specific application needs.\n",
        "\n",
        "### Disadvantages of MobileNet\n",
        "\n",
        "- **Reduced Accuracy**: While highly efficient, MobileNets generally offer lower accuracy compared to more complex models like ResNet or EfficientNet, particularly at lower resolution multipliers.\n",
        "- **Trade-off Between Speed and Accuracy**: The use of hyperparameters to reduce complexity often results in a trade-off, where increasing speed can significantly impact model accuracy.\n",
        "\n",
        "### Key Properties of MobileNet\n",
        "\n",
        "- **Optimized for Mobile Devices**: Designed from the ground up to support efficient operation on mobile and embedded devices.\n",
        "- **Flexible and Adaptable**: Its modular structure supports easy modifications to fit a broad spectrum of applications without significant redevelopment.\n",
        "- **Scalability**: MobileNets support efficient scaling mechanisms through width and resolution multipliers, making them adaptable to varying computational budgets.\n",
        "\n",
        "MobileNet continues to be a cornerstone in the development of mobile-optimized deep learning architectures, offering a unique blend of efficiency and moderate computational needs.\n"
      ],
      "metadata": {
        "id": "MT_i7jHT-NLZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asCQq3NO-Gb9"
      },
      "outputs": [],
      "source": []
    }
  ]
}