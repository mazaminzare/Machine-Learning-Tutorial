{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pretext Tasks in Self-Supervised Learning: In-Depth Mathematical Explanation\n",
        "\n",
        "## Core Concepts of Self-Supervised Learning\n",
        "\n",
        "### Pretext Tasks\n",
        "\n",
        "In self-supervised learning (SSL), pretext tasks are artificially created tasks that do not require human-labeled data. These tasks are designed to help the model learn useful representations of the data that can be transferred to downstream tasks. Here, we will delve into several common pretext tasks with detailed mathematical explanations, training procedures, and the advantages and drawbacks of each approach.\n",
        "\n",
        "#### 1. Image Inpainting\n",
        "\n",
        "**Objective**: Predict the missing parts of an image.\n",
        "\n",
        "**Mathematical Explanation**:\n",
        "\n",
        "- Let $\\mathbf{x} \\in \\mathbb{R}^{H \\times W \\times C}$ represent an input image with height $H$, width $W$, and $C$ color channels.\n",
        "- Define a binary mask $\\mathbf{m} \\in \\{0,1\\}^{H \\times W}$ where $\\mathbf{m}_{i,j} = 0$ indicates that the pixel at position $(i,j)$ is missing and needs to be predicted, and $\\mathbf{m}_{i,j} = 1$ indicates that the pixel is present.\n",
        "- The observed image can be denoted as $\\mathbf{x}' = \\mathbf{x} \\odot \\mathbf{m}$, where $\\odot$ is the element-wise multiplication.\n",
        "- The goal is to train a neural network $f_\\theta$ with parameters $\\theta$ to predict the missing pixels:\n",
        "  $$ \\hat{\\mathbf{x}} = f_\\theta(\\mathbf{x}') $$\n",
        "\n",
        "**Training**:\n",
        "\n",
        "- The loss function can be the mean squared error (MSE) between the predicted image and the original image:\n",
        "  $$ \\mathcal{L}(\\theta) = \\frac{1}{|\\mathcal{M}|} \\sum_{(i,j) \\in \\mathcal{M}} \\left( \\hat{\\mathbf{x}}_{i,j} - \\mathbf{x}_{i,j} \\right)^2 $$\n",
        "  where $\\mathcal{M} = \\{(i,j) : \\mathbf{m}_{i,j} = 0\\}$.\n",
        "\n",
        "**Derivatives**:\n",
        "\n",
        "- To minimize the loss function, we use gradient descent. The gradient of the loss with respect to the predictions is:\n",
        "  $$ \\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{x}}_{i,j}} = \\frac{2}{|\\mathcal{M}|} \\left( \\hat{\\mathbf{x}}_{i,j} - \\mathbf{x}_{i,j} \\right) $$\n",
        "- The gradient of the loss with respect to the model parameters $\\theta$ is obtained via the chain rule:\n",
        "  $$ \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{(i,j) \\in \\mathcal{M}} \\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{x}}_{i,j}} \\cdot \\frac{\\partial \\hat{\\mathbf{x}}_{i,j}}{\\partial \\theta} $$\n",
        "- The parameters are updated using gradient descent:\n",
        "  $$ \\theta \\leftarrow \\theta - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\theta} $$\n",
        "\n",
        "**Advantages**:\n",
        "\n",
        "- Utilizes the spatial structure of images effectively.\n",
        "- Helps the model learn context and relationships between different parts of the image.\n",
        "\n",
        "**Drawbacks**:\n",
        "\n",
        "- The effectiveness of the learned representations can depend on the type and size of the missing regions.\n",
        "- May not generalize well to other types of data without significant modifications.\n",
        "\n",
        "#### 2. Jigsaw Puzzles\n",
        "\n",
        "**Objective**: Rearrange scrambled patches of an image.\n",
        "\n",
        "**Mathematical Explanation**:\n",
        "\n",
        "- Divide the image $\\mathbf{x}$ into $N \\times N$ grid patches, resulting in $N^2$ patches.\n",
        "- Let $\\mathbf{x}_{i,j}$ be the patch at position $(i,j)$.\n",
        "- Scramble the patches using a permutation $\\pi$, giving a scrambled image $\\mathbf{x}^\\pi$.\n",
        "- The task is to predict the permutation $\\pi^{-1}$ that reconstructs the original image.\n",
        "- The model $f_\\theta$ is trained to output the correct permutation:\n",
        "  $$ \\hat{\\pi} = f_\\theta(\\mathbf{x}^\\pi) $$\n",
        "\n",
        "**Training**:\n",
        "\n",
        "- The loss function is typically the cross-entropy loss over the permutation indices:\n",
        "  $$ \\mathcal{L}(\\theta) = -\\sum_{k=1}^{N^2} \\log p_{\\theta}(\\pi^{-1}_k | \\mathbf{x}^\\pi) $$\n",
        "\n",
        "**Derivatives**:\n",
        "\n",
        "- The gradient of the cross-entropy loss with respect to the model parameters $\\theta$ is given by:\n",
        "  $$ \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = -\\sum_{k=1}^{N^2} \\left( \\frac{\\partial \\log p_{\\theta}(\\pi^{-1}_k | \\mathbf{x}^\\pi)}{\\partial \\theta} \\right) $$\n",
        "- Using the chain rule, the derivative can be expanded as:\n",
        "  $$ \\frac{\\partial \\log p_{\\theta}(\\pi^{-1}_k | \\mathbf{x}^\\pi)}{\\partial \\theta} = \\frac{1}{p_{\\theta}(\\pi^{-1}_k | \\mathbf{x}^\\pi)} \\cdot \\frac{\\partial p_{\\theta}(\\pi^{-1}_k | \\mathbf{x}^\\pi)}{\\partial \\theta} $$\n",
        "- The parameters are updated using gradient descent:\n",
        "  $$ \\theta \\leftarrow \\theta - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\theta} $$\n",
        "\n",
        "**Advantages**:\n",
        "\n",
        "- Forces the model to learn spatial relationships and dependencies between different parts of the image.\n",
        "- Simple to implement and effective in various computer vision tasks.\n",
        "\n",
        "**Drawbacks**:\n",
        "\n",
        "- Computationally expensive for large images due to the number of possible permutations.\n",
        "- The task might become trivial for small patch sizes, reducing the effectiveness of the learned representations.\n",
        "\n",
        "#### 3. Colorization\n",
        "\n",
        "**Objective**: Convert grayscale images to color images.\n",
        "\n",
        "**Mathematical Explanation**:\n",
        "\n",
        "- Convert the input image $\\mathbf{x}$ to grayscale, $\\mathbf{x}_{gray}$.\n",
        "- Train a model $f_\\theta$ to predict the color channels from the grayscale image:\n",
        "  $$ \\hat{\\mathbf{x}}_{color} = f_\\theta(\\mathbf{x}_{gray}) $$\n",
        "\n",
        "**Training**:\n",
        "\n",
        "- The loss function can be the MSE between the predicted and original color images:\n",
        "  $$ \\mathcal{L}(\\theta) = \\frac{1}{HWC} \\sum_{i=1}^{H} \\sum_{j=1}^{W} \\sum_{c=1}^{C} \\left( \\hat{\\mathbf{x}}_{i,j,c} - \\mathbf{x}_{i,j,c} \\right)^2 $$\n",
        "\n",
        "**Derivatives**:\n",
        "\n",
        "- The gradient of the loss with respect to the predictions is:\n",
        "  $$ \\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{x}}_{i,j,c}} = \\frac{2}{HWC} \\left( \\hat{\\mathbf{x}}_{i,j,c} - \\mathbf{x}_{i,j,c} \\right) $$\n",
        "- The gradient of the loss with respect to the model parameters $\\theta$ is obtained via the chain rule:\n",
        "  $$ \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{i=1}^{H} \\sum_{j=1}^{W} \\sum_{c=1}^{C} \\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\mathbf{x}}_{i,j,c}} \\cdot \\frac{\\partial \\hat{\\mathbf{x}}_{i,j,c}}{\\partial \\theta} $$\n",
        "- The parameters are updated using gradient descent:\n",
        "  $$ \\theta \\leftarrow \\theta - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\theta} $$\n",
        "\n",
        "**Advantages**:\n",
        "\n",
        "- Helps the model learn to generate realistic colors and understand semantic information in the image.\n",
        "- Effective in learning representations that transfer well to other vision tasks.\n",
        "\n",
        "**Drawbacks**:\n",
        "\n",
        "- The task is inherently ambiguous since multiple colorizations can be plausible for a single grayscale image.\n",
        "- May require additional regularization techniques to prevent the model from generating unrealistic colors.\n",
        "\n",
        "#### 4. Temporal Order Verification\n",
        "\n",
        "**Objective**: Determine the correct sequence of frames in a video.\n",
        "\n",
        "**Mathematical Explanation**:\n",
        "\n",
        "- Let $\\mathbf{X} = (\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_T)$ be a sequence of $T$ frames from a video.\n",
        "- Generate a shuffled sequence $\\mathbf{X}^\\pi$ using a permutation $\\pi$.\n",
        "- The task is to train a model $f_\\theta$ to predict the permutation $\\pi^{-1}$ that reconstructs the original sequence.\n",
        "- The model is trained to output the correct permutation:\n",
        "  $$ \\hat{\\pi} = f_\\theta(\\mathbf{X}^\\pi) $$\n",
        "\n",
        "**Training**:\n",
        "\n",
        "- The loss function is the cross-entropy loss over the permutation indices:\n",
        "  $$ \\mathcal{L}(\\theta) = -\\sum_{t=1}^{T} \\log p_{\\theta}(\\pi^{-1}_t | \\mathbf{X}^\\pi) $$\n",
        "\n",
        "**Derivatives**:\n",
        "\n",
        "- The gradient of the cross-entropy loss with respect to the model parameters $\\theta$ is given by:\n",
        "  $$ \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = -\\sum_{t=1}^{T} \\left( \\frac{\\partial \\log p_{\\theta}(\\pi^{-1}_t | \\mathbf{X}^\\pi)}{\\partial \\theta} \\right) $$\n",
        "- Using the chain rule, the derivative can be expanded as:\n",
        "  $$ \\frac{\\partial \\log p_{\\theta}(\\pi^{-1}_t | \\mathbf{X}^\\pi)}{\\partial \\theta} = \\frac{1}{p_{\\theta}(\\pi^{-1}_t | \\mathbf{X}^\\pi)} \\cdot \\frac{\\partial p_{\\theta}(\\pi^{-1}_t | \\mathbf{X}^\\pi)}{\\partial \\theta} $$\n",
        "- The parameters are updated using gradient descent:\n",
        "  $$ \\theta \\leftarrow \\theta - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\theta} $$\n",
        "\n",
        "**Advantages**:\n",
        "\n",
        "- Encourages the model to understand temporal dependencies and motion in videos.\n",
        "- Useful for tasks that require temporal understanding, such as action recognition.\n",
        "\n",
        "**Drawbacks**:\n",
        "\n",
        "- The task can become challenging with longer video sequences due to the increased complexity of permutations.\n",
        "- Requires careful selection of frame permutations to avoid trivial solutions that do not contribute to meaningful representation learning.\n",
        "\n",
        "By designing these pretext tasks, self-supervised learning encourages models to learn meaningful and transferable representations of the data, which can significantly improve performance on downstream tasks. Each pretext task leverages the inherent structure and relationships within the data to guide the learning process.\n"
      ],
      "metadata": {
        "id": "xktF_Q4iolHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpg5OdlgokxV"
      },
      "outputs": [],
      "source": []
    }
  ]
}